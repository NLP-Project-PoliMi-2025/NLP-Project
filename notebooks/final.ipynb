{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aee1561e",
   "metadata": {},
   "source": [
    "# Group Assignment NLP course 2024/2025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203a2f15",
   "metadata": {},
   "source": [
    "## Group: NLP Processors\n",
    "* Ginefra Paolo\n",
    "* Onori Ferdinando\n",
    "* Missana Martina\n",
    "* Uhrich Robin\n",
    "\n",
    "##  Dataset: [Strategic Game Chess](https://huggingface.co/datasets/laion/strategic_game_chess)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788bbe48",
   "metadata": {},
   "source": [
    "The dataset used contains data on chess games generated through self-play **Stockfish** engine using **Fugaku** (a supercomputer in Kobe, Japan) adding initial moves to expand the diversity. It contains **3.2 billion games** with approximately 608 billion moves.\n",
    "\n",
    "Due to computational constraints we decided to work just on the first parquet file of the dataset, containing the first **100.000 games**. \n",
    "\n",
    "Each game in the dataset is composed of three columns:\n",
    "* **Move**: a sequence of all the moves made during the game.\n",
    "\n",
    "* **Termination**: the condition under which the game ended. Possible values include: \n",
    "    - `CHECKMATE`\n",
    "    - `INSUFFICIENT MATERIAL`\n",
    "    - `FIVEFOLD_REPETITION`\n",
    "    - `SEVENTYFIVE_MOVES`\n",
    "    - `STALEMATE`\n",
    "* **Result**: result of the game\n",
    "    - `1-0`         (White wins)\n",
    "    - `1/2-1/2`     (Draw)\n",
    "    - `0-1`         (Black wins)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18361cee",
   "metadata": {},
   "source": [
    " #### **Data Wrangling**\n",
    "\n",
    "To facilitate the use of the dataset and ensure all necessary information is available for the project, a set of Parquet files was created with the following structure:\n",
    "* **Moves**\n",
    "\n",
    "* **Termination**\n",
    "\n",
    "* **Result**\n",
    "\n",
    "* **Pieces**: the piece moved in every move\n",
    "\n",
    "* **Captures**: the type of piece captured (if any) at each move.\n",
    "\n",
    "* **Checks**: a boolean value indicating whether a move resulted in a check (`true` or `false`)\n",
    "\n",
    "* **Next_move**: the move sequence shifted by one position, useful for predictive modeling tasks\n",
    "\n",
    "* **Result_seqs**: a repeated sequence of the final result, aligned with the length of the move sequence for each game\n",
    "\n",
    "\n",
    "In addition, two YAML files were created to support data processing:\n",
    "\n",
    "- **Move Lookup Table**  \n",
    "\n",
    "  A mapping of all possible moves to unique integer identifiers.\n",
    "\n",
    "- **Result Lookup Table**  \n",
    "\n",
    "  A mapping of game results (`1-0`, `0-1`, `1/2-1/2`) to numerical labels, useful for classification tasks.\n",
    "\n",
    "\n",
    "All the files used were uploaded on **Hugging Face**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "993f4ef4",
   "metadata": {},
   "source": [
    "#### TODOs:\n",
    "* explaining why we used just one parquet file\n",
    "* creation of the dataset\n",
    "* our goal for the project (how much chess lang is a natural lang)\n",
    "* disclaimer that we stick the dataset as closely as possible with assumingnot  having knowledge ofunderlyingmodelof chess"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04b28d8",
   "metadata": {},
   "source": [
    "### 1. Preliminary Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef483155",
   "metadata": {},
   "source": [
    "#### TODOs:\n",
    "* Data Exploration (type of data, structure, vocaboulary, ...) - verbose stuff\n",
    "* graph - verbose stuff\n",
    "* Zipf's Law\n",
    "* usage of move visualizer/ move plotter\n",
    "* clustering (Australia  plot) (Paolo explaining if  clusters make sens)\n",
    "* word2vec and embeddings (Paolo)\n",
    "* move distribution(martina)\n",
    "* FEN distribution (Ferdinando)\n",
    "* skipgrams n-grams(matrices, dendrograms(?))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b740de",
   "metadata": {},
   "source": [
    "### 2. Training Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc68fed",
   "metadata": {},
   "source": [
    "#### TODOs:\n",
    "* LAMA\n",
    "* LSTM\n",
    "* RAG (Paolo)\n",
    "* Transformer (plots)\n",
    "* Zeroshot-multishot(?)(Ferdinando)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b07f05ac",
   "metadata": {},
   "source": [
    "### 3. Possible Extensions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46ee36a",
   "metadata": {},
   "source": [
    "#### TODOs:\n",
    "* chessbots with game entropy etc. (lstm,ferdinando,voice)\n",
    "\n",
    "(menu and intuition)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72dacaa8",
   "metadata": {},
   "source": [
    "### 4. Conclusions (?)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee1d89b",
   "metadata": {},
   "source": [
    "* adding knowledge should result in better performances...\n",
    "* computationalconstraintsssss\n",
    "* chess grammar"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
