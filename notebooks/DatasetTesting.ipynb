{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a48cffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('..')\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe411589",
   "metadata": {},
   "outputs": [],
   "source": [
    "from project.dataset.ChessDataset import ChessDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd502228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading parquet file @  ./data/games_0001/train_100K.parquet  with columns  ['Moves', 'pieces', 'captures']\n",
      "Loaded 70000 rows and 3 columns\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building lookup tables: 100%|██████████| 3/3 [00:02<00:00,  1.09it/s]\n",
      "Converting columns to indices: 100%|██████████| 3/3 [00:04<00:00,  1.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading parquet file @  ./data/games_0001/test_100K.parquet  with columns  ['Moves', 'pieces', 'captures']\n",
      "Loaded 10001 rows and 3 columns\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building lookup tables: 100%|██████████| 3/3 [00:00<00:00,  8.78it/s]\n",
      "Converting columns to indices: 100%|██████████| 3/3 [00:00<00:00,  4.97it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = ChessDataset(\n",
    "    parquette_path='./data/games_0001/train_100K.parquet',\n",
    "    inputColumns=['Moves'],\n",
    "    labelColumns=['pieces', 'captures'])\n",
    "datasetTest = ChessDataset(\n",
    "    parquette_path='./data/games_0001/test_100K.parquet',\n",
    "    inputColumns=['Moves'],\n",
    "    labelColumns=['pieces', 'captures'],\n",
    "    lookupReference=dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ee8b9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "lookUpsTrain = dataset.lookup_tables\n",
    "lookUpsTest = datasetTest.lookup_tables\n",
    "\n",
    "for column in lookUpsTest:\n",
    "    lookUpTrain = lookUpsTrain[column]\n",
    "    lookUpTest = lookUpsTest[column]\n",
    "\n",
    "    #Check that all keys in lookupTest have the same value as in lookupTrain\n",
    "    for key in lookUpTest:\n",
    "        if key in lookUpTrain:\n",
    "            assert lookUpTrain[key] == lookUpTest[key], f\"Key {key} in lookupTest has different value than in lookupTrain: {lookUpTrain[key]} != {lookUpTest[key]}\"\n",
    "\n",
    "    #Check that all keys in lookupTrain have the same value as in lookupTest\n",
    "    for key in lookUpTrain:\n",
    "        if key in lookUpTest:\n",
    "            assert lookUpTrain[key] == lookUpTest[key], f\"Key {key} in lookupTrain has different value than in lookupTest: {lookUpTrain[key]} != {lookUpTest[key]}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96574f7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,  14,\n",
       "          15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,  28,\n",
       "          29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  23,  39,  40,  41,\n",
       "          42,  26,  43,  44,  45,  46,  47,  28,  48,  49,  50,  51,  52,  53,\n",
       "          54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,\n",
       "          68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,  47,  79,  80,\n",
       "          81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,\n",
       "          95,  96,  97,  70,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107,\n",
       "         108, 109, 110, 111, 112, 113, 114,  65, 115, 116, 117, 118, 119, 120,\n",
       "         121, 122, 123, 124, 125,  38, 126, 127, 128, 109, 129, 130, 131, 132,\n",
       "         133, 134, 135, 136, 137, 138,  60, 139, 140, 141, 142, 143, 144, 145,\n",
       "         100, 146, 147, 148, 149, 150, 151, 152, 153],\n",
       "        [  1,   1,   2,   3,   1,   1,   3,   1,   3,   2,   1,   1,   2,   1,\n",
       "           3,   2,   4,   2,   3,   3,   2,   3,   1,   3,   1,   3,   3,   3,\n",
       "           4,   2,   3,   2,   5,   2,   6,   4,   2,   6,   4,   2,   2,   6,\n",
       "           3,   3,   5,   5,   5,   4,   1,   3,   3,   5,   1,   4,   4,   5,\n",
       "           2,   3,   2,   5,   2,   5,   3,   3,   3,   6,   3,   1,   3,   6,\n",
       "           5,   6,   1,   3,   5,   3,   5,   6,   1,   5,   1,   5,   2,   3,\n",
       "           2,   1,   2,   6,   2,   1,   3,   6,   1,   6,   6,   5,   5,   1,\n",
       "           3,   5,   5,   5,   5,   5,   1,   6,   6,   5,   5,   6,   6,   5,\n",
       "           1,   1,   1,   5,   1,   1,   1,   6,   1,   5,   6,   5,   3,   5,\n",
       "           6,   5,   6,   5,   6,   5,   5,   5,   5,   6,   6,   6,   5,   6,\n",
       "           5,   6,   6,   6,   5,   6,   6,   6,   5,   6,   6,   6,   6,   6,\n",
       "           6,   6,   6,   6,   6,   6,   5,   6,   5],\n",
       "        [  1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   2,   2,   1,   1,\n",
       "           1,   1,   1,   1,   1,   1,   2,   3,   1,   1,   4,   4,   3,   1,\n",
       "           1,   1,   1,   2,   1,   1,   1,   1,   1,   1,   1,   1,   2,   1,\n",
       "           3,   1,   1,   1,   5,   5,   1,   1,   1,   1,   1,   1,   6,   6,\n",
       "           1,   1,   1,   1,   1,   2,   1,   1,   2,   1,   1,   1,   1,   1,\n",
       "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   2,\n",
       "           1,   1,   1,   1,   4,   3,   1,   1,   1,   1,   1,   1,   2,   1,\n",
       "           1,   1,   1,   1,   1,   1,   2,   2,   1,   1,   1,   1,   1,   1,\n",
       "           1,   1,   2,   1,   1,   2,   2,   1,   1,   1,   1,   1,   1,   4,\n",
       "           1,   1,   1,   1,   1,   1,   1,   2,   5,   2,   1,   1,   1,   1,\n",
       "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
       "           1,   1,   1,   1,   1,   1,   1,   1,   1]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "row = dataset.df.iloc[0]\n",
    "\n",
    "# Get the input and label columns\n",
    "inputs = row[dataset.inputColumns + dataset.labelColumns].values\n",
    "#Convert the lists to np.arrays\n",
    "inputs  = [torch.tensor(x) for x in inputs]\n",
    "# If you want to concatenate all tensors in the inputs list into a single tensor:\n",
    "inputs = torch.vstack([x if x.dim() > 0 else x.unsqueeze(0) for x in inputs])\n",
    "\n",
    "labels = row[dataset.labelColumns].values\n",
    "\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "09110240",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "564125c35191419db1196b7c0f20e43c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/64.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Polimi\\Master\\2Sem\\NLP-Project\\.conda\\Lib\\site-packages\\huggingface_hub\\file_download.py:144: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Paolo\\.cache\\huggingface\\hub\\datasets--PaoloGinefra03--ChessGamesForNlp. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8f30e9f6cbd46b39205487679efc69d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train_100K.parquet:   0%|          | 0.00/47.0M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5df1d9ecd32413b9af97d3c1eec0417",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "val_100K.parquet:   0%|          | 0.00/13.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16def1423d6c4f7bbfcabf512c5dabe4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test_100K.parquet:   0%|          | 0.00/6.72M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c047bf56d2b4a1bb9ed0ee2273202e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/70000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "072294ed7c4749ecb82c9fa5d1cb1fb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/19999 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6a44d12bb7b4f8bb60c0eb0125ae039",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/10001 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"PaoloGinefra03/ChessGamesForNlp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ea95173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset with columns  ['Moves', 'pieces', 'captures']\n",
      "Loaded 70000 rows and 3 columns\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building lookup tables: 100%|██████████| 3/3 [00:02<00:00,  1.13it/s]\n",
      "Converting columns to indices: 100%|██████████| 3/3 [00:04<00:00,  1.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset with columns  ['Moves', 'pieces', 'captures']\n",
      "Loaded 10001 rows and 3 columns\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building lookup tables: 100%|██████████| 3/3 [00:00<00:00,  7.94it/s]\n",
      "Converting columns to indices: 100%|██████████| 3/3 [00:01<00:00,  2.58it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = ChessDataset(\n",
    "    dataset=ds['train'],\n",
    "    inputColumns=['Moves'],\n",
    "    labelColumns=['pieces', 'captures'],\n",
    "    lookupReference=None,\n",
    ")\n",
    "datasetTest = ChessDataset(\n",
    "    dataset=ds['test'],\n",
    "    inputColumns=['Moves'],\n",
    "    labelColumns=['pieces', 'captures'],\n",
    "    lookupReference=dataset,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
