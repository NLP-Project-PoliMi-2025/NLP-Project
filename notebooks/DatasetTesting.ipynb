{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a48cffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('..')\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe411589",
   "metadata": {},
   "outputs": [],
   "source": [
    "from project.dataset.ChessDataset import ChessDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cd502228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading parquet file @  ./data/games_0001/train_100K.parquet  with columns  ['Moves', 'pieces', 'captures']\n",
      "Loaded 70000 rows and 3 columns\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building lookup tables: 100%|██████████| 3/3 [00:02<00:00,  1.17it/s]\n",
      "Converting columns to indices: 100%|██████████| 3/3 [00:04<00:00,  1.64s/it]\n"
     ]
    }
   ],
   "source": [
    "dataset = ChessDataset('./data/games_0001/train_100K.parquet', ['Moves'], ['pieces', 'captures'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1ee8b9d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
       "           14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
       "           28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  22,  38,  39,  40,\n",
       "           41,  25,  42,  43,  44,  45,  46,  27,  47,  48,  49,  50,  51,  52,\n",
       "           53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,\n",
       "           67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  46,  78,  79,\n",
       "           80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,  92,  93,\n",
       "           94,  95,  96,  69,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106,\n",
       "          107, 108, 109, 110, 111, 112, 113,  64, 114, 115, 116, 117, 118, 119,\n",
       "          120, 121, 122, 123, 124,  37, 125, 126, 127, 108, 128, 129, 130, 131,\n",
       "          132, 133, 134, 135, 136, 137,  59, 138, 139, 140, 141, 142, 143, 144,\n",
       "           99, 145, 146, 147, 148, 149, 150, 151, 152])],\n",
       " [tensor([0, 0, 1, 2, 0, 0, 2, 0, 2, 1, 0, 0, 1, 0, 2, 1, 3, 1, 2, 2, 1, 2, 0, 2,\n",
       "          0, 2, 2, 2, 3, 1, 2, 1, 4, 1, 5, 3, 1, 5, 3, 1, 1, 5, 2, 2, 4, 4, 4, 3,\n",
       "          0, 2, 2, 4, 0, 3, 3, 4, 1, 2, 1, 4, 1, 4, 2, 2, 2, 5, 2, 0, 2, 5, 4, 5,\n",
       "          0, 2, 4, 2, 4, 5, 0, 4, 0, 4, 1, 2, 1, 0, 1, 5, 1, 0, 2, 5, 0, 5, 5, 4,\n",
       "          4, 0, 2, 4, 4, 4, 4, 4, 0, 5, 5, 4, 4, 5, 5, 4, 0, 0, 0, 4, 0, 0, 0, 5,\n",
       "          0, 4, 5, 4, 2, 4, 5, 4, 5, 4, 5, 4, 4, 4, 4, 5, 5, 5, 4, 5, 4, 5, 5, 5,\n",
       "          4, 5, 5, 5, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 4, 5, 4]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0,\n",
       "          3, 3, 2, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 2, 0, 0, 0, 4, 4,\n",
       "          0, 0, 0, 0, 0, 0, 5, 5, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 3, 2, 0, 0, 0, 0, 0, 0,\n",
       "          1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0,\n",
       "          0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 1, 4, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760dc170",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.getLookupTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "96574f7c",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Sizes of tensors must match except in dimension 0. Expected size 135 but got size 1 for tensor number 1 in the list.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      8\u001b[39m inputs  = [torch.tensor(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m inputs]\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# If you want to concatenate all tensors in the inputs list into a single tensor:\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m inputs = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdim\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m>\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m.\u001b[49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m labels = row[dataset.labelColumns].values\n\u001b[32m     14\u001b[39m inputs\n",
      "\u001b[31mRuntimeError\u001b[39m: Sizes of tensors must match except in dimension 0. Expected size 135 but got size 1 for tensor number 1 in the list."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "row = dataset.df.iloc[0]\n",
    "\n",
    "# Get the input and label columns\n",
    "inputs = row[dataset.inputColums + dataset.labelColumns].values\n",
    "#Convert the lists to np.arrays\n",
    "inputs  = [torch.tensor(x) for x in inputs]\n",
    "# If you want to concatenate all tensors in the inputs list into a single tensor:\n",
    "inputs = torch.vstack([x if x.dim() > 0 else x.unsqueeze(0) for x in inputs])\n",
    "\n",
    "labels = row[dataset.labelColumns].values\n",
    "\n",
    "inputs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
