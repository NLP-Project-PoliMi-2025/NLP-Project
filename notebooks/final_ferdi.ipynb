{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zero-Few Shot\n",
    "Comparison between a standard GPT2 model and the same model after been fineTuned with 90k matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-11): 12 x GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D(nf=2304, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=768)\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D(nf=3072, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=3072)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "import torch\n",
    "import os\n",
    "\n",
    "#Standard GPT2: Tokenizer and model\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "\n",
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2\", trust_remote_code=True)\n",
    "model.eval()\n",
    "\n",
    "\n",
    "# Fine-tuned GPT2: Tokenizer1 and model1\n",
    "model_path = \"../ChessBOT_GPT2/Model90K/model\" #Modify as soon the model made it to HuggingFace\n",
    "tokenizer1 = GPT2Tokenizer.from_pretrained(model_path,use_safetensors=True)\n",
    "if tokenizer1.pad_token is None:\n",
    "    tokenizer1.pad_token = tokenizer1.eos_token\n",
    "\n",
    "model1 = GPT2LMHeadModel.from_pretrained(model_path,use_safetensors=True,trust_remote_code=True)\n",
    "model1.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model,tokenizer,prompt, max_new_tokens=100, temperature=0.7, top_k=50, top_p=0.95):\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", padding=True)\n",
    "    prompt_length = len(inputs[\"input_ids\"][0])\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            inputs[\"input_ids\"],\n",
    "            attention_mask=inputs[\"attention_mask\"],  \n",
    "            max_length=prompt_length + max_new_tokens,\n",
    "            temperature=temperature,\n",
    "            top_k=top_k,\n",
    "            top_p=top_p,\n",
    "            do_sample=True,\n",
    "            pad_token_id=tokenizer.eos_token_id  \n",
    "        )\n",
    "    \n",
    "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    \n",
    "    new_text = generated_text[len(tokenizer.decode(inputs[\"input_ids\"][0], skip_special_tokens=True)):]\n",
    "    \n",
    "    return new_text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chess\n",
    "## if starting_fen is None, the board will be initialized to the starting position \n",
    "def get_fen_from_uci_sequence(uci_sequence, starting_fen=None):\n",
    "\n",
    "    \n",
    "    if starting_fen:\n",
    "        board = chess.Board(starting_fen)\n",
    "    else:\n",
    "        board = chess.Board()  \n",
    "    \n",
    "    moves = uci_sequence.strip().split()\n",
    "    \n",
    "    for move_str in moves:\n",
    "        \n",
    "        try:\n",
    "            move = chess.Move.from_uci(move_str)\n",
    "            \n",
    "            if move in board.legal_moves:\n",
    "                board.push(move)\n",
    "\n",
    "            else:\n",
    "                print(f\"Moves {move_str} not legal!\")\n",
    "                print(\"Moves sequence was interrupted.\")\n",
    "                break\n",
    "        except ValueError:\n",
    "            print(f\"Moves {move_str} not in UCI format!\")\n",
    "            print(\"Moves sequence was interrupted.\")\n",
    "            break\n",
    "    \n",
    "    # Stampa la scacchiera nello stato attuale\n",
    "    print(\"\\nState of the board:\")\n",
    "    print(board)\n",
    "    \n",
    "    # Ritorna la FEN finale\n",
    "    final_fen = board.fen()\n",
    "    print(f\"\\nFEN: {final_fen}\")\n",
    "    \n",
    "    return final_fen, board"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Status\n",
    "Selection of the Hystory of the game from the start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "State of the board:\n",
      "r n . q k . . r\n",
      "p p . . p p B p\n",
      ". . . p . n p .\n",
      ". . p . . . . .\n",
      ". . P N . . b .\n",
      ". . . P . . . .\n",
      "P P . . P P P P\n",
      "R . . Q K B N R\n",
      "\n",
      "FEN: rn1qk2r/pp2ppBp/3p1np1/2p5/2PN2b1/3P4/PP2PPPP/R2QKBNR b KQkq - 2 7\n"
     ]
    }
   ],
   "source": [
    "movesHistory=\"c2c4 c7c5 b1a3 g8f6 d2d3 d7d6 a3b5 g7g6 c1h6 f8g7 h6g7 c8g4 b5d4\"\n",
    "\n",
    "FEN,board=get_fen_from_uci_sequence(movesHistory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ZeroShot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt1 = f\"\"\"You are a chess assistant. Given a sequence of UCI moves, suggest two reasonable next moves for the side to play.\n",
    "Remeber the first moves of the sequence I gave is played by white, the second by black and so on.\n",
    "\n",
    "Moves so far:\n",
    "{movesHistory}\n",
    "\n",
    "Your suggestions:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard GPT2 response:\n",
      "1. Black has to play with some movement.\n",
      "\n",
      "2. White can play with some movement.\n",
      "\n",
      "3. White has to play with movement.\n",
      "\n",
      "4. White can play with movement.\n",
      "\n",
      "5. White can\n",
      "\n",
      "Fine-tuned GPT2 response:\n",
      "d1d2 d8d7 d7a4 a4a7 a7a5 d2b4 f6e4 f1d3 e4d6 e1e2 g4d7 h1c1 d6\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stdGPT2Response=generate_text(model,tokenizer,prompt1,50)\n",
    "print(f\"Standard GPT2 response:\\n{stdGPT2Response}\\n\")\n",
    "\n",
    "fineTuneGPT2Response=generate_text(model1,tokenizer1,prompt1,50)\n",
    "print(f\"Fine-tuned GPT2 response:\\n{fineTuneGPT2Response}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The part of the prompt asking for 2 possibile moves got completely ignored from both the models, the finetuned one simply start try playing for both the player.\n",
    "The slice of the prompt: \"Remeber the first moves of the sequence I gave is played by white, the second by black and so on\" is crucial for the second model otherwise the response often start with a moves of the wrong player\n",
    "\n",
    "The difference between the two model is clear stdGPT2 doesn't get what is a UCI format by itself and as a single move show some random char, on the other hand the other model seem not to understand anymore the request of having two suggestion nor having a suggestion fot the next move as it start simply to play.\n",
    "\n",
    "Sometimes the finetuned model start the response with a single char followed by a space and then a sequence of UCI moves, if the single CHAR is ignored the following move is usually valid\n",
    "\n",
    "\n",
    "\n",
    "Here a longer moves History to see if the model can handle it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "State of the board:\n",
      ". . . . . k . .\n",
      ". p . R . p p p\n",
      "p . . b . . . .\n",
      ". . . . . . Q .\n",
      ". . . . . P . .\n",
      ". . . . . . . P\n",
      "P . . . . K P .\n",
      ". . . q . . . .\n",
      "\n",
      "FEN: 5k2/1p1R1ppp/p2b4/6Q1/5P2/7P/P4KP1/3q4 b - - 27 43\n"
     ]
    }
   ],
   "source": [
    "movesHistoryLong=\"d2d4 d7d5 c2c4 e7e6 b1c3 c7c5 c4d5 e6d5 g1f3 g8f6 c1g5 c5d4 f3d4 f8e7 e2e3 b8c6 f1e2 e8g8 e1g1 a7a6 a1c1 f8e8 e2f3 c8e6 c3e2 c6e5 e2f4 e5f3 d1f3 e6g4 f3g3 d8d7 g5f6 e7f6 h2h3 g4f5 d4f5 d7f5 c1c5 a8d8 f1d1 f6b2 c5d5 d8d5 f4d5 f5c2 d5e7 g8f8 d1d7 c2c5 e7d5 b2e5 f2f4 e5d6 g3g5 e8e3 d5e3 c5e3 g1f1 e3d3 f1f2 d3d4 f2f3 d4d1 f3f2 d1d2 f2f1 d2d1 f1f2 d1d2 f2f1 d2d3 f1f2 d3d2 f2f1 d2d3 f1f2 d3d2 f2f1 d2d3 f1f2 d3d4 f2f3 d4d1 f3f2\"\n",
    "\n",
    "FEN,board=get_fen_from_uci_sequence(movesHistoryLong)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "promptL = f\"\"\"You are a chess assistant. Given a sequence of UCI moves, suggest two reasonable next moves for the side to play.\n",
    "Remeber the first moves of the sequence I gave is played by white, the second by black and so on.\n",
    "\n",
    "Moves so far:\n",
    "{movesHistoryLong}\n",
    "\n",
    "Your suggestions:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard GPT2 response:\n",
      "This is the most reasonable move, given the sequence I gave.\n",
      "\n",
      "The last move is played by white, the second by black and so on.\n",
      "\n",
      "Remeber the first moves of the sequence I gave is played by white\n",
      "\n",
      "Fine-tuned GPT2 response:\n",
      "1 f2d3 f1 f1f2 d3d2 f2f3 d1f2 d3d4 f3d2 f2 d7d5 f2 f2f3 d3d2 f1 f\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stdGPT2Response=generate_text(model,tokenizer,promptL,50)\n",
    "print(f\"Standard GPT2 response:\\n{stdGPT2Response}\\n\")\n",
    "\n",
    "fineTuneGPT2Response=generate_text(model1,tokenizer1,promptL,50)\n",
    "print(f\"Fine-tuned GPT2 response:\\n{fineTuneGPT2Response}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Already with an history not huge compared to the one in the dataset also the fineTuned model start messing up proposing unlegal moves,sometimes moving a piece like it was another, and also start showing \"UCI moves\" of 2 char; that probably caused by the limited context GPT2 can handle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FewShot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try now if some FewShot could improve the performance especially of stdGPT2 which didn't bring any useful prediction with ZeroShot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "prompt2=f\"\"\"\n",
    "You are a chess assistant. Given a sequence of UCI moves, suggest two plausible next moves for the player to play.\n",
    "Remeber the first moves of the sequence I gave is played by white, the second by black and so on.\n",
    "    \n",
    "Example 1  \n",
    "Moves so far:  \n",
    "d2d4 g8f6 c2c4 e7e6 g1f3 d7d5 b1c3 f8e7 c1g5 h7h6  \n",
    "Suggestions: g5h4 e2e3  \n",
    "\n",
    "Example 2  \n",
    "Moves so far:  \n",
    "e2e4 e7e5 g1f3 b8c6 f1b5 a7a6 b5a4 g8f6 e1g1 f8e7 f1e1 b7b5 a4b3  \n",
    "Suggestions: c2c3 f3g5  \n",
    "\n",
    "Now it's your turn:\n",
    "\n",
    "Moves so far:  \n",
    "{movesHistory}  \n",
    "Suggestions: \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard GPT2 response:\n",
      "Example 3  \n",
      "\n",
      "Moves so far:  \n",
      "\n",
      "e2e4 e7e5  \n",
      "\n",
      "Ditto.\n",
      "\n",
      "Moves so far:  \n",
      "\n",
      "e2e4 e7e\n",
      "\n",
      "Fine-tuned GPT2 response:\n",
      "1c1 d8e8 g7f5 f5e4 d3e2 e2a6 a2a4 e4f5 g4f3 g6f5 e7d7 a6b7 b7c\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stdGPT2Response=generate_text(model,tokenizer,prompt2,50)\n",
    "print(f\"Standard GPT2 response:\\n{stdGPT2Response}\\n\")\n",
    "\n",
    "fineTuneGPT2Response=generate_text(model1,tokenizer1,prompt2,50)\n",
    "print(f\"Fine-tuned GPT2 response:\\n{fineTuneGPT2Response}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problems seen with GPT2 stay the same, also the thing it say are not coherent with the movesHistory: \"c2c4 c7c5 b1a3 g8f6 d2d3 d7d6 a3b5 g7g6 c1h6 f8g7 h6g7 c8g4 b5d4\"\n",
    "\n",
    "The fineTuned model here doesn't improve in any way and more often start the sequence with a 3 char which doesn't represent any moves in the UCI format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FineTuned ZeroShot evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chess\n",
    "import re\n",
    "import os\n",
    "\n",
    "def evaluate_legal_moves_from_file(filename, model, tokenizer, num_samples=10000, temperature=0.7, verbose=True):\n",
    "    \"\"\"\n",
    "    Calculates statistics on legal move predictions from the model.\n",
    "    \n",
    "    Args:\n",
    "        filename (str): Path to the file with move sequences, one per line\n",
    "        model: Language model to evaluate\n",
    "        tokenizer: Tokenizer associated with the model\n",
    "        num_samples (int): Maximum number of samples to evaluate\n",
    "        temperature (float): Temperature to use for generation\n",
    "        verbose (bool): If True, prints details during execution\n",
    "    \n",
    "    Returns:\n",
    "        dict: Dictionary with prediction statistics\n",
    "    \"\"\"\n",
    "    if not os.path.exists(filename):\n",
    "        raise FileNotFoundError(f\"File {filename} not found\")\n",
    "    \n",
    "    # Read move sequences from file\n",
    "    with open(filename, 'r') as f:\n",
    "        move_sequences = [line.strip() for line in f if line.strip()]\n",
    "    \n",
    "    # Limit the number of samples if necessary\n",
    "    if num_samples and num_samples < len(move_sequences):\n",
    "        move_sequences = move_sequences[:num_samples]\n",
    "    \n",
    "    # Statistics\n",
    "    total_predictions = 0\n",
    "    legal_moves = 0\n",
    "    illegal_moves = 0\n",
    "    invalid_format = 0\n",
    "    stats_by_length = {}\n",
    "    \n",
    "    # Pattern to extract the first UCI move from the model's response\n",
    "    move_pattern = r'([a-h][1-8][a-h][1-8][qrbnkQRBNK]?)'\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"Evaluating {len(move_sequences)} move sequences...\")\n",
    "    \n",
    "    # Process each sequence\n",
    "    for i, sequence in enumerate(move_sequences):\n",
    "        if verbose and i % 10 == 0:\n",
    "            print(f\"Processing sequence {i+1}/{len(move_sequences)}...\")\n",
    "        \n",
    "        # Set up the chessboard with the sequence moves\n",
    "        board = chess.Board()\n",
    "        moves = sequence.split()\n",
    "        \n",
    "        # Apply all moves to the board\n",
    "        valid_sequence = True\n",
    "        for move_str in moves:\n",
    "            try:\n",
    "                move = chess.Move.from_uci(move_str)\n",
    "                if move in board.legal_moves:\n",
    "                    board.push(move)\n",
    "                else:\n",
    "                    valid_sequence = False\n",
    "                    if verbose:\n",
    "                        print(f\"Invalid move in sequence {i+1}: {move_str}\")\n",
    "                    break\n",
    "            except ValueError:\n",
    "                valid_sequence = False\n",
    "                if verbose:\n",
    "                    print(f\"Invalid move format in sequence {i+1}: {move_str}\")\n",
    "                break\n",
    "        \n",
    "        # Skip invalid sequences\n",
    "        if not valid_sequence:\n",
    "            continue\n",
    "        \n",
    "        # Generate the prompt for the model\n",
    "        prompt = f\"\"\"You are a chess assistant. Given a sequence of UCI moves, suggest two reasonable next moves for the side to play.\n",
    "        Remember the first moves of the sequence I gave is played by white, the second by black and so on.\n",
    "\n",
    "        Moves so far:\n",
    "        {sequence}\n",
    "\n",
    "        Your suggestions:\"\"\"\n",
    "        \n",
    "        # Generate the prediction\n",
    "        prediction = generate_text(model, tokenizer, prompt, max_new_tokens=10, temperature=temperature)\n",
    "        \n",
    "        # Extract the first move in UCI format from the prediction\n",
    "        match = re.search(move_pattern, prediction)\n",
    "        predicted_move = match.group(1) if match else None\n",
    "        \n",
    "        # Track statistics by sequence length\n",
    "        seq_length = len(moves)\n",
    "        if seq_length not in stats_by_length:\n",
    "            stats_by_length[seq_length] = {\n",
    "                'total': 0, 'legal': 0, 'illegal': 0, 'invalid': 0\n",
    "            }\n",
    "        \n",
    "        # Check if the predicted move is valid\n",
    "        total_predictions += 1\n",
    "        stats_by_length[seq_length]['total'] += 1\n",
    "        \n",
    "        if predicted_move is None:\n",
    "            invalid_format += 1\n",
    "            stats_by_length[seq_length]['invalid'] += 1\n",
    "            if verbose:\n",
    "                print(f\"Prediction without valid UCI format: '{prediction}'\")\n",
    "        else:\n",
    "            try:\n",
    "                move = chess.Move.from_uci(predicted_move)\n",
    "                if move in board.legal_moves:\n",
    "                    legal_moves += 1\n",
    "                    stats_by_length[seq_length]['legal'] += 1\n",
    "                    if verbose:\n",
    "                        print(f\"Legal move predicted: {predicted_move}\")\n",
    "                else:\n",
    "                    illegal_moves += 1\n",
    "                    stats_by_length[seq_length]['illegal'] += 1\n",
    "                    if verbose:\n",
    "                        print(f\"Illegal move predicted: {predicted_move}\")\n",
    "            except ValueError:\n",
    "                invalid_format += 1\n",
    "                stats_by_length[seq_length]['invalid'] += 1\n",
    "                if verbose:\n",
    "                    print(f\"Invalid predicted move format: {predicted_move}\")\n",
    "    \n",
    "    # Calculate final statistics\n",
    "    legal_rate = legal_moves / total_predictions * 100 if total_predictions > 0 else 0\n",
    "    illegal_rate = illegal_moves / total_predictions * 100 if total_predictions > 0 else 0\n",
    "    invalid_rate = invalid_format / total_predictions * 100 if total_predictions > 0 else 0\n",
    "    \n",
    "    # Results\n",
    "    results = {\n",
    "        'total_predictions': total_predictions,\n",
    "        'legal_moves': legal_moves,\n",
    "        'illegal_moves': illegal_moves,\n",
    "        'invalid_format': invalid_format,\n",
    "        'legal_rate': legal_rate,\n",
    "        'illegal_rate': illegal_rate,\n",
    "        'invalid_rate': invalid_rate,\n",
    "        'stats_by_length': stats_by_length\n",
    "    }\n",
    "    \n",
    "    # Print statistics report\n",
    "    print(\"\\n--- PREDICTION STATISTICS ---\")\n",
    "    print(f\"Total predictions: {total_predictions}\")\n",
    "    print(f\"Legal moves: {legal_moves} ({legal_rate:.2f}%)\")\n",
    "    print(f\"Illegal moves: {illegal_moves} ({illegal_rate:.2f}%)\")\n",
    "    print(f\"Invalid format: {invalid_format} ({invalid_rate:.2f}%)\")\n",
    "        \n",
    "    print(\"\\n--- DETAIL BY SEQUENCE LENGTH ---\")\n",
    "    for length, stats in sorted(stats_by_length.items()):\n",
    "        if stats['total'] > 0:\n",
    "            legal_pct = stats['legal'] / stats['total'] * 100\n",
    "            print(f\"Length {length}: {stats['legal']}/{stats['total']} legal moves ({legal_pct:.2f}%)\")\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file \"testing_sequence.txt\" has been generated from 10k matches not used in the fineTuning of the model, it contain the first moves for each games: the lenght of each sequence has been randomically chosen by random.randint between 1 and 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- PREDICTION STATISTICS ---\n",
      "Total predictions: 10000\n",
      "Legal moves: 3274 (32.74%)\n",
      "Illegal moves: 6726 (67.26%)\n",
      "Invalid format: 0 (0.00%)\n",
      "\n",
      "--- DETAIL BY SEQUENCE LENGTH ---\n",
      "Length 1: 261/462 legal moves (56.49%)\n",
      "Length 2: 143/504 legal moves (28.37%)\n",
      "Length 3: 180/506 legal moves (35.57%)\n",
      "Length 4: 182/507 legal moves (35.90%)\n",
      "Length 5: 160/557 legal moves (28.73%)\n",
      "Length 6: 123/491 legal moves (25.05%)\n",
      "Length 7: 137/503 legal moves (27.24%)\n",
      "Length 8: 113/469 legal moves (24.09%)\n",
      "Length 9: 199/498 legal moves (39.96%)\n",
      "Length 10: 105/472 legal moves (22.25%)\n",
      "Length 11: 190/493 legal moves (38.54%)\n",
      "Length 12: 101/484 legal moves (20.87%)\n",
      "Length 13: 237/463 legal moves (51.19%)\n",
      "Length 14: 114/498 legal moves (22.89%)\n",
      "Length 15: 223/494 legal moves (45.14%)\n",
      "Length 16: 132/520 legal moves (25.38%)\n",
      "Length 17: 199/532 legal moves (37.41%)\n",
      "Length 18: 137/505 legal moves (27.13%)\n",
      "Length 19: 214/513 legal moves (41.72%)\n",
      "Length 20: 124/529 legal moves (23.44%)\n",
      "Percentage of legal moves: 32.74%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "results = evaluate_legal_moves_from_file(\n",
    "    \"../ChessBOT_GPT2/testing_sequences.txt\", \n",
    "    model1,                 \n",
    "    tokenizer1,             \n",
    "    temperature=0.7,      \n",
    "    num_samples=10000, #The 10k squences are in the file were not used in the tuning\n",
    "    verbose=False         \n",
    ")\n",
    "\n",
    "print(f\"Percentage of legal moves: {results['legal_rate']:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save all these information so they can be retriven if the notebook encount some issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"legalRate.txt\", 'w') as f:\n",
    "        # Write overall statistics\n",
    "        f.write(\"=== PREDICTION STATISTICS ===\\n\")\n",
    "        f.write(f\"Total predictions: {results['total_predictions']}\\n\")\n",
    "        f.write(f\"Legal moves: {results['legal_moves']} ({results['legal_rate']:.2f}%)\\n\")\n",
    "        f.write(f\"Illegal moves: {results['illegal_moves']} ({results['illegal_rate']:.2f}%)\\n\")\n",
    "        f.write(f\"Invalid format: {results['invalid_format']} ({results['invalid_rate']:.2f}%)\\n\\n\")\n",
    "        \n",
    "        # Write statistics by sequence length\n",
    "        f.write(\"=== DETAIL BY SEQUENCE LENGTH ===\\n\")\n",
    "        for length, stats in sorted(results['stats_by_length'].items()):\n",
    "            if stats['total'] > 0:\n",
    "                legal_pct = stats['legal'] / stats['total'] * 100\n",
    "                f.write(f\"Length {length}: {stats['legal']}/{stats['total']} legal moves ({legal_pct:.2f}%)\\n\")\n",
    "        \n",
    "        # Write timestamp\n",
    "        import datetime\n",
    "        f.write(f\"\\nResults generated on: {datetime.datetime.now()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just for showing the result without having to rerun the book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== PREDICTION STATISTICS ===\n",
      "Total predictions: 10000\n",
      "Legal moves: 3274 (32.74%)\n",
      "Illegal moves: 6726 (67.26%)\n",
      "Invalid format: 0 (0.00%)\n",
      "\n",
      "=== DETAIL BY SEQUENCE LENGTH ===\n",
      "Length 1: 261/462 legal moves (56.49%)\n",
      "Length 2: 143/504 legal moves (28.37%)\n",
      "Length 3: 180/506 legal moves (35.57%)\n",
      "Length 4: 182/507 legal moves (35.90%)\n",
      "Length 5: 160/557 legal moves (28.73%)\n",
      "Length 6: 123/491 legal moves (25.05%)\n",
      "Length 7: 137/503 legal moves (27.24%)\n",
      "Length 8: 113/469 legal moves (24.09%)\n",
      "Length 9: 199/498 legal moves (39.96%)\n",
      "Length 10: 105/472 legal moves (22.25%)\n",
      "Length 11: 190/493 legal moves (38.54%)\n",
      "Length 12: 101/484 legal moves (20.87%)\n",
      "Length 13: 237/463 legal moves (51.19%)\n",
      "Length 14: 114/498 legal moves (22.89%)\n",
      "Length 15: 223/494 legal moves (45.14%)\n",
      "Length 16: 132/520 legal moves (25.38%)\n",
      "Length 17: 199/532 legal moves (37.41%)\n",
      "Length 18: 137/505 legal moves (27.13%)\n",
      "Length 19: 214/513 legal moves (41.72%)\n",
      "Length 20: 124/529 legal moves (23.44%)\n",
      "\n",
      "Results generated on: 2025-05-23 19:01:19.880611\n"
     ]
    }
   ],
   "source": [
    "    filename=\"../ChessBOT_GPT2/legalRate.txt\"\n",
    "    try:\n",
    "        with open(filename, 'r') as f:\n",
    "            content = f.read()\n",
    "            print(content)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File '{filename}' non trovato.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Errore durante la lettura del file: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion\n",
    "\n",
    "For the Chess-bot will use a zeroShot method as it seem to be more consistent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ChessBot\n",
    "Here we use our fineTuned model with the ZeroShot prompting to create a basic chess bot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This two function can be used alternatively in \"my_moves_generator\", at the moment the one used is the one with_probs as it allow to generate some different moves and cover those time when some predicted moves happen not to be valid; generate_text instaed simply generate one response from the model. Both function here are used with the ZeroShot prompting tried before.\n",
    "The utilization of \"generate_text_with_probs\" made the model a bit more determinist but more robust "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text_with_probs(model, tokenizer, prompt, num_top_tokens=10, sequence_length=8, temperature=0.7):\n",
    "    \"\"\"\n",
    "    Generate few sequences based on the most probable tokens from the model's output.\n",
    "    At the end it concatenates the generated sequences into a single string.\n",
    "\n",
    "    Args:\n",
    "        num_top_tokens: Number of most probable tokens to consider\n",
    "        sequence_length: Length of the sequences to generate for each starting token\n",
    "    \"\"\"\n",
    "    \n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "    input_ids = inputs.input_ids\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        logits = model(**inputs).logits[:, -1, :]\n",
    "        \n",
    "        probs = torch.softmax(logits / temperature, dim=-1)\n",
    "        \n",
    "        top_probs, top_indices = torch.topk(probs, num_top_tokens)\n",
    "        \n",
    "        all_sequences = []\n",
    "        \n",
    "        for i in range(num_top_tokens):\n",
    "            \n",
    "            top_token_id = top_indices[0][i].item()\n",
    "        \n",
    "            new_input_ids = torch.cat([input_ids, top_indices[0][i].unsqueeze(0).unsqueeze(0)], dim=1)\n",
    "        \n",
    "            outputs = model.generate(\n",
    "                new_input_ids,\n",
    "                max_length=len(new_input_ids[0]) + sequence_length,\n",
    "                do_sample=True,\n",
    "                temperature=temperature,\n",
    "                num_return_sequences=1,\n",
    "                pad_token_id=tokenizer.eos_token_id\n",
    "            )\n",
    "            \n",
    "            full_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "            \n",
    "            prompt_text = tokenizer.decode(input_ids[0], skip_special_tokens=True)\n",
    "            generated_text = full_text[len(prompt_text):].strip()\n",
    "            \n",
    "            all_sequences.append(generated_text)\n",
    "        \n",
    "    result = \" \".join(all_sequences)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model,tokenizer,prompt, max_new_tokens=100, temperature=0.7, top_k=50, top_p=0.95):\n",
    "    \n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", padding=True)\n",
    "    prompt_length = len(inputs[\"input_ids\"][0])\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            inputs[\"input_ids\"],\n",
    "            attention_mask=inputs[\"attention_mask\"], \n",
    "            max_length=prompt_length + max_new_tokens,\n",
    "            temperature=temperature,\n",
    "            top_k=top_k,\n",
    "            top_p=top_p,\n",
    "            do_sample=True,\n",
    "            pad_token_id=tokenizer.eos_token_id \n",
    "        )\n",
    "    \n",
    "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    \n",
    "    new_text = generated_text[len(tokenizer.decode(inputs[\"input_ids\"][0], skip_special_tokens=True)):]\n",
    "    \n",
    "    return new_text.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the function necessary for the bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chess\n",
    "import chess.svg\n",
    "from IPython.display import display, SVG, clear_output\n",
    "\n",
    "class ChessGame:\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initializes a chess game with a human player and a bot.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.board = chess.Board()  \n",
    "        \n",
    "        self.move_history = [] \n",
    "        self.move_history_str = \"\"  \n",
    "        self.fen_history = [self.board.fen()]  \n",
    "        self.human_color = chess.WHITE  \n",
    "        \n",
    "    def display_board(self):\n",
    "        svg = chess.svg.board(self.board, size=400)\n",
    "        clear_output(wait=True)\n",
    "        display(SVG(svg))\n",
    "        \n",
    "    \n",
    "    def get_current_fen(self):\n",
    "        return self.board.fen()\n",
    "    \n",
    "    def make_move(self, uci_move_str):\n",
    "        try:\n",
    "            move = chess.Move.from_uci(uci_move_str)\n",
    "            if move in self.board.legal_moves:\n",
    "                self.move_history.append(uci_move_str)\n",
    "                \n",
    "                if self.move_history_str:\n",
    "                    self.move_history_str += \" \" + uci_move_str\n",
    "                else:\n",
    "                    self.move_history_str = uci_move_str\n",
    "                \n",
    "                self.board.push(move)\n",
    "                \n",
    "                self.fen_history.append(self.board.fen())\n",
    "                \n",
    "                turn = \"Black\" if self.board.turn == chess.BLACK else \"White\"\n",
    "                print(f\"Played move: {uci_move_str}\")\n",
    "                print(f\"It's {turn} turn now.\")\n",
    "                \n",
    "                if self.board.is_check():\n",
    "                    print(\"CHECK!\")\n",
    "                if self.board.is_checkmate():\n",
    "                    print(\"CHECKMATE!\")\n",
    "                elif self.board.is_stalemate():\n",
    "                    print(\"STALECHECK!\")\n",
    "                    \n",
    "                return True\n",
    "            else:\n",
    "                print(f\"Move {uci_move_str} not legal!\")\n",
    "                return False\n",
    "        except ValueError:\n",
    "            print(f\"Move {uci_move_str} not valid!\")\n",
    "            return False\n",
    "    \n",
    "    def find_first_valid_move(self, moves_string):\n",
    "        \"\"\"\n",
    "        Finds the first valid move in a string of moves.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            moves = moves_string.strip().split()\n",
    "            \n",
    "            for move_str in moves:\n",
    "                try:\n",
    "                    move = chess.Move.from_uci(move_str)\n",
    "                    if move in self.board.legal_moves:\n",
    "                        return move_str\n",
    "                except ValueError:\n",
    "                    continue\n",
    "            \n",
    "            return None\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def get_bot_move(self, moves_generator_func):\n",
    "        \"\"\"\n",
    "        Obtain a valid move for the bot using the move generator function.\n",
    "        \"\"\"\n",
    "        current_fen = self.get_current_fen()\n",
    "        \n",
    "       \n",
    "        moves_string = moves_generator_func(self.move_history_str)\n",
    "        \n",
    "        if not moves_string:\n",
    "            print(\"The generating function didn't generate any moves.\")\n",
    "            return None\n",
    "       \n",
    "        valid_move = self.find_first_valid_move(moves_string)\n",
    "        \n",
    "        if valid_move:\n",
    "            print(f\"The bot chose: {valid_move}\")\n",
    "            return valid_move\n",
    "        else:\n",
    "            print(\"No valid moves generated by the bot.\")\n",
    "            return None\n",
    "    \n",
    "    def play_game(self, moves_generator_func, human_plays_white=True):\n",
    "        \n",
    "        self.human_color = chess.WHITE if human_plays_white else chess.BLACK\n",
    "        \n",
    "        print(\"=== NEW CHESS MATCH ===\")\n",
    "        print(\"you're playing with: \" + (\"White\" if human_plays_white else \"Black\"))\n",
    "        print(\"digit 'q' to end the match, 'f' to see the current FEN, 'h' to see the move history\")\n",
    "        if not human_plays_white and self.board.turn == chess.WHITE:\n",
    "            print(\"The bot start\")\n",
    "            bot_move = self.get_bot_move(moves_generator_func)\n",
    "            if bot_move:\n",
    "                self.make_move(bot_move)\n",
    "        \n",
    "        while not self.board.is_game_over():\n",
    "            self.display_board()\n",
    "            \n",
    "            current_player = \"You\" if self.board.turn == self.human_color else \"bot\"\n",
    "            print(f\"\\nis your turn: {'White' if self.board.turn == chess.WHITE else 'Black'} ({current_player})\")\n",
    "            \n",
    "            if self.board.turn == self.human_color:\n",
    "                uci_move = input(\"Insert your moves (UCI format, es. e2e4) [input q to end the match]: \")\n",
    "                \n",
    "                if uci_move.lower() == 'q':\n",
    "                    print(\"Match finishes.\")\n",
    "                    break\n",
    "                elif uci_move.lower() == 'f':\n",
    "                    print(f\"Actual FEN: {self.get_current_fen()}\")\n",
    "                    continue\n",
    "                elif uci_move.lower() == 'h':\n",
    "                    print(f\"Moves history: {self.move_history_str}\")\n",
    "                    continue\n",
    "                \n",
    "                move_success = self.make_move(uci_move)\n",
    "                if not move_success:\n",
    "                    print(\"Unvalid move, retry.\")\n",
    "                    continue\n",
    "            else:\n",
    "                bot_move = self.get_bot_move(moves_generator_func)\n",
    "                \n",
    "                if not bot_move:\n",
    "                    print(\"The bot didnt manage to think about a moves, match ended.\")\n",
    "                    break\n",
    "                \n",
    "                self.make_move(bot_move)\n",
    "        \n",
    "        self.display_board()\n",
    "        \n",
    "        if self.board.is_checkmate():\n",
    "            winner = \"White\" if self.board.turn == chess.BLACK else \"Black\"\n",
    "            print(f\"CHECKMATE! {winner} win!\")\n",
    "        elif self.board.is_stalemate():\n",
    "            print(\"No one wins ); it's a STALEMATE!\")\n",
    "        elif self.board.is_insufficient_material():\n",
    "            print(\"INSUFFICIENT MATERIAL! No one wins );\")\n",
    "        \n",
    "        print(\"\\nMove History:\")\n",
    "        for i, move in enumerate(self.move_history):\n",
    "            print(f\"{i//2 + 1}{'. ' if i%2==0 else '... '}{move}\")\n",
    "        \n",
    "        print(f\"Full history: {self.move_history_str}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The core function of the bot: it uses the generate_text functions to let the model create some possible moves for the game. \n",
    "\n",
    "It is possible to see also the generate moves of the model which doesn't make it to the board in \"chess_bot_logs/bot_log.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def my_moves_generator(moves_history):\n",
    "    \"\"\"\n",
    "    It generates the next moves for the bot based on the moves history.\n",
    "    It uses a language model to generate the moves.\n",
    "\n",
    "    Within the function is possible to modify whether the bot plays follwing the most probable moves or the most probable ones.\n",
    "    \n",
    "    If needed, there's a file which contain al the predictions of the model.\n",
    "    The file is called \"bot_log.txt\" and is located in the \"chess_bot_logs\" directory.\n",
    "    \"\"\"\n",
    "    \n",
    "    log_dir = \"chess_bot_logs\"\n",
    "    if not os.path.exists(log_dir):\n",
    "        os.makedirs(log_dir)\n",
    "    \n",
    "    log_file = os.path.join(log_dir, f\"bot_log.txt\")\n",
    "    \n",
    "    prompt = f\"\"\"You are a chess assistant. Given a sequence of UCI moves, suggest two reasonable next moves for the side to play.\n",
    "    Remember the first move of the sequence I gave is played by white, the second by black and so on.\n",
    "\n",
    "    Moves so far:\n",
    "    {moves_history}\n",
    "\n",
    "    Your suggestions:\"\"\"\n",
    "    \n",
    "    ### Change the commented line below to choose between the two functions\n",
    "    ### the one with probs seems to be a bit better in handling some configurations the other one\n",
    "    ### sometimes fail\n",
    "    #generated_moves = generate_text(model, tokenizer, prompt, 50)\n",
    "    generated_moves = generate_text_with_probs(model1, tokenizer, prompt)\n",
    "    \n",
    "    with open(log_file, \"a\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"-\" * 80 + \"\\n\")\n",
    "        f.write(f\"PARTITA IN CORSO\\n\")\n",
    "        f.write(f\"MOSSE FINORA: {moves_history}\\n\")\n",
    "        f.write(f\"PROMPT: {prompt}\\n\")\n",
    "        f.write(f\"RISPOSTA DEL MODELLO: {generated_moves}\\n\")\n",
    "        f.write(\"-\" * 80 + \"\\n\\n\")\n",
    "    \n",
    "    return generated_moves\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" viewBox=\"0 0 390 390\" width=\"400\" height=\"400\"><desc><pre>r n b q k b n r\n",
       "p p p p p p p p\n",
       ". . . . . . . .\n",
       ". . . . . . . .\n",
       ". . . . . . . .\n",
       ". . . . . . . .\n",
       "P P P P P P P P\n",
       "R N B Q K B N R</pre></desc><defs><g id=\"white-pawn\" class=\"white pawn\"><path d=\"M22.5 9c-2.21 0-4 1.79-4 4 0 .89.29 1.71.78 2.38C17.33 16.5 16 18.59 16 21c0 2.03.94 3.84 2.41 5.03-3 1.06-7.41 5.55-7.41 13.47h23c0-7.92-4.41-12.41-7.41-13.47 1.47-1.19 2.41-3 2.41-5.03 0-2.41-1.33-4.5-3.28-5.62.49-.67.78-1.49.78-2.38 0-2.21-1.79-4-4-4z\" fill=\"#fff\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\"/></g><g id=\"white-knight\" class=\"white knight\" fill=\"none\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M 22,10 C 32.5,11 38.5,18 38,39 L 15,39 C 15,30 25,32.5 23,18\" style=\"fill:#ffffff; stroke:#000000;\"/><path d=\"M 24,18 C 24.38,20.91 18.45,25.37 16,27 C 13,29 13.18,31.34 11,31 C 9.958,30.06 12.41,27.96 11,28 C 10,28 11.19,29.23 10,30 C 9,30 5.997,31 6,26 C 6,24 12,14 12,14 C 12,14 13.89,12.1 14,10.5 C 13.27,9.506 13.5,8.5 13.5,7.5 C 14.5,6.5 16.5,10 16.5,10 L 18.5,10 C 18.5,10 19.28,8.008 21,7 C 22,7 22,10 22,10\" style=\"fill:#ffffff; stroke:#000000;\"/><path d=\"M 9.5 25.5 A 0.5 0.5 0 1 1 8.5,25.5 A 0.5 0.5 0 1 1 9.5 25.5 z\" style=\"fill:#000000; stroke:#000000;\"/><path d=\"M 15 15.5 A 0.5 1.5 0 1 1 14,15.5 A 0.5 1.5 0 1 1 15 15.5 z\" transform=\"matrix(0.866,0.5,-0.5,0.866,9.693,-5.173)\" style=\"fill:#000000; stroke:#000000;\"/></g><g id=\"white-bishop\" class=\"white bishop\" fill=\"none\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><g fill=\"#fff\" stroke-linecap=\"butt\"><path d=\"M9 36c3.39-.97 10.11.43 13.5-2 3.39 2.43 10.11 1.03 13.5 2 0 0 1.65.54 3 2-.68.97-1.65.99-3 .5-3.39-.97-10.11.46-13.5-1-3.39 1.46-10.11.03-13.5 1-1.354.49-2.323.47-3-.5 1.354-1.94 3-2 3-2zM15 32c2.5 2.5 12.5 2.5 15 0 .5-1.5 0-2 0-2 0-2.5-2.5-4-2.5-4 5.5-1.5 6-11.5-5-15.5-11 4-10.5 14-5 15.5 0 0-2.5 1.5-2.5 4 0 0-.5.5 0 2zM25 8a2.5 2.5 0 1 1-5 0 2.5 2.5 0 1 1 5 0z\"/></g><path d=\"M17.5 26h10M15 30h15m-7.5-14.5v5M20 18h5\" stroke-linejoin=\"miter\"/></g><g id=\"white-rook\" class=\"white rook\" fill=\"#fff\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M9 39h27v-3H9v3zM12 36v-4h21v4H12zM11 14V9h4v2h5V9h5v2h5V9h4v5\" stroke-linecap=\"butt\"/><path d=\"M34 14l-3 3H14l-3-3\"/><path d=\"M31 17v12.5H14V17\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\"/><path d=\"M31 29.5l1.5 2.5h-20l1.5-2.5\"/><path d=\"M11 14h23\" fill=\"none\" stroke-linejoin=\"miter\"/></g><g id=\"white-queen\" class=\"white queen\" fill=\"#fff\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M8 12a2 2 0 1 1-4 0 2 2 0 1 1 4 0zM24.5 7.5a2 2 0 1 1-4 0 2 2 0 1 1 4 0zM41 12a2 2 0 1 1-4 0 2 2 0 1 1 4 0zM16 8.5a2 2 0 1 1-4 0 2 2 0 1 1 4 0zM33 9a2 2 0 1 1-4 0 2 2 0 1 1 4 0z\"/><path d=\"M9 26c8.5-1.5 21-1.5 27 0l2-12-7 11V11l-5.5 13.5-3-15-3 15-5.5-14V25L7 14l2 12zM9 26c0 2 1.5 2 2.5 4 1 1.5 1 1 .5 3.5-1.5 1-1.5 2.5-1.5 2.5-1.5 1.5.5 2.5.5 2.5 6.5 1 16.5 1 23 0 0 0 1.5-1 0-2.5 0 0 .5-1.5-1-2.5-.5-2.5-.5-2 .5-3.5 1-2 2.5-2 2.5-4-8.5-1.5-18.5-1.5-27 0z\" stroke-linecap=\"butt\"/><path d=\"M11.5 30c3.5-1 18.5-1 22 0M12 33.5c6-1 15-1 21 0\" fill=\"none\"/></g><g id=\"white-king\" class=\"white king\" fill=\"none\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M22.5 11.63V6M20 8h5\" stroke-linejoin=\"miter\"/><path d=\"M22.5 25s4.5-7.5 3-10.5c0 0-1-2.5-3-2.5s-3 2.5-3 2.5c-1.5 3 3 10.5 3 10.5\" fill=\"#fff\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\"/><path d=\"M11.5 37c5.5 3.5 15.5 3.5 21 0v-7s9-4.5 6-10.5c-4-6.5-13.5-3.5-16 4V27v-3.5c-3.5-7.5-13-10.5-16-4-3 6 5 10 5 10V37z\" fill=\"#fff\"/><path d=\"M11.5 30c5.5-3 15.5-3 21 0m-21 3.5c5.5-3 15.5-3 21 0m-21 3.5c5.5-3 15.5-3 21 0\"/></g><g id=\"black-pawn\" class=\"black pawn\"><path d=\"M22.5 9c-2.21 0-4 1.79-4 4 0 .89.29 1.71.78 2.38C17.33 16.5 16 18.59 16 21c0 2.03.94 3.84 2.41 5.03-3 1.06-7.41 5.55-7.41 13.47h23c0-7.92-4.41-12.41-7.41-13.47 1.47-1.19 2.41-3 2.41-5.03 0-2.41-1.33-4.5-3.28-5.62.49-.67.78-1.49.78-2.38 0-2.21-1.79-4-4-4z\" fill=\"#000\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\"/></g><g id=\"black-knight\" class=\"black knight\" fill=\"none\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M 22,10 C 32.5,11 38.5,18 38,39 L 15,39 C 15,30 25,32.5 23,18\" style=\"fill:#000000; stroke:#000000;\"/><path d=\"M 24,18 C 24.38,20.91 18.45,25.37 16,27 C 13,29 13.18,31.34 11,31 C 9.958,30.06 12.41,27.96 11,28 C 10,28 11.19,29.23 10,30 C 9,30 5.997,31 6,26 C 6,24 12,14 12,14 C 12,14 13.89,12.1 14,10.5 C 13.27,9.506 13.5,8.5 13.5,7.5 C 14.5,6.5 16.5,10 16.5,10 L 18.5,10 C 18.5,10 19.28,8.008 21,7 C 22,7 22,10 22,10\" style=\"fill:#000000; stroke:#000000;\"/><path d=\"M 9.5 25.5 A 0.5 0.5 0 1 1 8.5,25.5 A 0.5 0.5 0 1 1 9.5 25.5 z\" style=\"fill:#ececec; stroke:#ececec;\"/><path d=\"M 15 15.5 A 0.5 1.5 0 1 1 14,15.5 A 0.5 1.5 0 1 1 15 15.5 z\" transform=\"matrix(0.866,0.5,-0.5,0.866,9.693,-5.173)\" style=\"fill:#ececec; stroke:#ececec;\"/><path d=\"M 24.55,10.4 L 24.1,11.85 L 24.6,12 C 27.75,13 30.25,14.49 32.5,18.75 C 34.75,23.01 35.75,29.06 35.25,39 L 35.2,39.5 L 37.45,39.5 L 37.5,39 C 38,28.94 36.62,22.15 34.25,17.66 C 31.88,13.17 28.46,11.02 25.06,10.5 L 24.55,10.4 z \" style=\"fill:#ececec; stroke:none;\"/></g><g id=\"black-bishop\" class=\"black bishop\" fill=\"none\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M9 36c3.39-.97 10.11.43 13.5-2 3.39 2.43 10.11 1.03 13.5 2 0 0 1.65.54 3 2-.68.97-1.65.99-3 .5-3.39-.97-10.11.46-13.5-1-3.39 1.46-10.11.03-13.5 1-1.354.49-2.323.47-3-.5 1.354-1.94 3-2 3-2zm6-4c2.5 2.5 12.5 2.5 15 0 .5-1.5 0-2 0-2 0-2.5-2.5-4-2.5-4 5.5-1.5 6-11.5-5-15.5-11 4-10.5 14-5 15.5 0 0-2.5 1.5-2.5 4 0 0-.5.5 0 2zM25 8a2.5 2.5 0 1 1-5 0 2.5 2.5 0 1 1 5 0z\" fill=\"#000\" stroke-linecap=\"butt\"/><path d=\"M17.5 26h10M15 30h15m-7.5-14.5v5M20 18h5\" stroke=\"#fff\" stroke-linejoin=\"miter\"/></g><g id=\"black-rook\" class=\"black rook\" fill=\"#000\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M9 39h27v-3H9v3zM12.5 32l1.5-2.5h17l1.5 2.5h-20zM12 36v-4h21v4H12z\" stroke-linecap=\"butt\"/><path d=\"M14 29.5v-13h17v13H14z\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\"/><path d=\"M14 16.5L11 14h23l-3 2.5H14zM11 14V9h4v2h5V9h5v2h5V9h4v5H11z\" stroke-linecap=\"butt\"/><path d=\"M12 35.5h21M13 31.5h19M14 29.5h17M14 16.5h17M11 14h23\" fill=\"none\" stroke=\"#fff\" stroke-width=\"1\" stroke-linejoin=\"miter\"/></g><g id=\"black-queen\" class=\"black queen\" fill=\"#000\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><g fill=\"#000\" stroke=\"none\"><circle cx=\"6\" cy=\"12\" r=\"2.75\"/><circle cx=\"14\" cy=\"9\" r=\"2.75\"/><circle cx=\"22.5\" cy=\"8\" r=\"2.75\"/><circle cx=\"31\" cy=\"9\" r=\"2.75\"/><circle cx=\"39\" cy=\"12\" r=\"2.75\"/></g><path d=\"M9 26c8.5-1.5 21-1.5 27 0l2.5-12.5L31 25l-.3-14.1-5.2 13.6-3-14.5-3 14.5-5.2-13.6L14 25 6.5 13.5 9 26zM9 26c0 2 1.5 2 2.5 4 1 1.5 1 1 .5 3.5-1.5 1-1.5 2.5-1.5 2.5-1.5 1.5.5 2.5.5 2.5 6.5 1 16.5 1 23 0 0 0 1.5-1 0-2.5 0 0 .5-1.5-1-2.5-.5-2.5-.5-2 .5-3.5 1-2 2.5-2 2.5-4-8.5-1.5-18.5-1.5-27 0z\" stroke-linecap=\"butt\"/><path d=\"M11 38.5a35 35 1 0 0 23 0\" fill=\"none\" stroke-linecap=\"butt\"/><path d=\"M11 29a35 35 1 0 1 23 0M12.5 31.5h20M11.5 34.5a35 35 1 0 0 22 0M10.5 37.5a35 35 1 0 0 24 0\" fill=\"none\" stroke=\"#fff\"/></g><g id=\"black-king\" class=\"black king\" fill=\"none\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M22.5 11.63V6\" stroke-linejoin=\"miter\"/><path d=\"M22.5 25s4.5-7.5 3-10.5c0 0-1-2.5-3-2.5s-3 2.5-3 2.5c-1.5 3 3 10.5 3 10.5\" fill=\"#000\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\"/><path d=\"M11.5 37c5.5 3.5 15.5 3.5 21 0v-7s9-4.5 6-10.5c-4-6.5-13.5-3.5-16 4V27v-3.5c-3.5-7.5-13-10.5-16-4-3 6 5 10 5 10V37z\" fill=\"#000\"/><path d=\"M20 8h5\" stroke-linejoin=\"miter\"/><path d=\"M32 29.5s8.5-4 6.03-9.65C34.15 14 25 18 22.5 24.5l.01 2.1-.01-2.1C20 18 9.906 14 6.997 19.85c-2.497 5.65 4.853 9 4.853 9M11.5 30c5.5-3 15.5-3 21 0m-21 3.5c5.5-3 15.5-3 21 0m-21 3.5c5.5-3 15.5-3 21 0\" stroke=\"#fff\"/></g></defs><rect x=\"7.5\" y=\"7.5\" width=\"375\" height=\"375\" fill=\"none\" stroke=\"#212121\" stroke-width=\"15\"/><g transform=\"translate(20, 1) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M23.328 10.016q-1.742 0-2.414.398-.672.398-.672 1.36 0 .765.5 1.218.508.445 1.375.445 1.196 0 1.914-.843.727-.852.727-2.258v-.32zm2.867-.594v4.992h-1.437v-1.328q-.492.797-1.227 1.18-.734.375-1.797.375-1.343 0-2.14-.75-.79-.758-.79-2.024 0-1.476.985-2.226.992-.75 2.953-.75h2.016V8.75q0-.992-.656-1.531-.649-.547-1.829-.547-.75 0-1.46.18-.711.18-1.368.539V6.062q.79-.304 1.532-.453.742-.156 1.445-.156 1.898 0 2.836.984.937.985.937 2.985z\"/></g><g transform=\"translate(20, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M23.328 10.016q-1.742 0-2.414.398-.672.398-.672 1.36 0 .765.5 1.218.508.445 1.375.445 1.196 0 1.914-.843.727-.852.727-2.258v-.32zm2.867-.594v4.992h-1.437v-1.328q-.492.797-1.227 1.18-.734.375-1.797.375-1.343 0-2.14-.75-.79-.758-.79-2.024 0-1.476.985-2.226.992-.75 2.953-.75h2.016V8.75q0-.992-.656-1.531-.649-.547-1.829-.547-.75 0-1.46.18-.711.18-1.368.539V6.062q.79-.304 1.532-.453.742-.156 1.445-.156 1.898 0 2.836.984.937.985.937 2.985z\"/></g><g transform=\"translate(65, 1) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.922 10.047q0-1.586-.656-2.485-.649-.906-1.79-.906-1.14 0-1.796.906-.649.899-.649 2.485 0 1.586.649 2.492.656.898 1.797.898 1.14 0 1.789-.898.656-.906.656-2.492zm-4.89-3.055q.452-.781 1.14-1.156.695-.383 1.656-.383 1.594 0 2.586 1.266 1 1.265 1 3.328 0 2.062-1 3.328-.992 1.266-2.586 1.266-.96 0-1.656-.375-.688-.383-1.14-1.164v1.312h-1.446V2.258h1.445z\"/></g><g transform=\"translate(65, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.922 10.047q0-1.586-.656-2.485-.649-.906-1.79-.906-1.14 0-1.796.906-.649.899-.649 2.485 0 1.586.649 2.492.656.898 1.797.898 1.14 0 1.789-.898.656-.906.656-2.492zm-4.89-3.055q.452-.781 1.14-1.156.695-.383 1.656-.383 1.594 0 2.586 1.266 1 1.265 1 3.328 0 2.062-1 3.328-.992 1.266-2.586 1.266-.96 0-1.656-.375-.688-.383-1.14-1.164v1.312h-1.446V2.258h1.445z\"/></g><g transform=\"translate(110, 1) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M25.96 6v1.344q-.608-.336-1.226-.5-.609-.172-1.234-.172-1.398 0-2.172.89-.773.883-.773 2.485 0 1.601.773 2.492.774.883 2.172.883.625 0 1.234-.164.618-.172 1.227-.508v1.328q-.602.281-1.25.422-.64.14-1.367.14-1.977 0-3.14-1.242-1.165-1.242-1.165-3.351 0-2.14 1.172-3.367 1.18-1.227 3.227-1.227.664 0 1.296.14.633.134 1.227.407z\"/></g><g transform=\"translate(110, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M25.96 6v1.344q-.608-.336-1.226-.5-.609-.172-1.234-.172-1.398 0-2.172.89-.773.883-.773 2.485 0 1.601.773 2.492.774.883 2.172.883.625 0 1.234-.164.618-.172 1.227-.508v1.328q-.602.281-1.25.422-.64.14-1.367.14-1.977 0-3.14-1.242-1.165-1.242-1.165-3.351 0-2.14 1.172-3.367 1.18-1.227 3.227-1.227.664 0 1.296.14.633.134 1.227.407z\"/></g><g transform=\"translate(155, 1) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.973 6.992V2.258h1.437v12.156h-1.437v-1.312q-.453.78-1.149 1.164-.687.375-1.656.375-1.586 0-2.586-1.266-.992-1.266-.992-3.328 0-2.063.992-3.328 1-1.266 2.586-1.266.969 0 1.656.383.696.375 1.149 1.156zm-4.899 3.055q0 1.586.649 2.492.656.898 1.797.898 1.14 0 1.796-.898.657-.906.657-2.492 0-1.586-.657-2.485-.656-.906-1.796-.906-1.141 0-1.797.906-.649.899-.649 2.485z\"/></g><g transform=\"translate(155, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.973 6.992V2.258h1.437v12.156h-1.437v-1.312q-.453.78-1.149 1.164-.687.375-1.656.375-1.586 0-2.586-1.266-.992-1.266-.992-3.328 0-2.063.992-3.328 1-1.266 2.586-1.266.969 0 1.656.383.696.375 1.149 1.156zm-4.899 3.055q0 1.586.649 2.492.656.898 1.797.898 1.14 0 1.796-.898.657-.906.657-2.492 0-1.586-.657-2.485-.656-.906-1.796-.906-1.141 0-1.797.906-.649.899-.649 2.485z\"/></g><g transform=\"translate(200, 1) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M26.555 9.68v.703h-6.61q.094 1.484.89 2.265.806.774 2.235.774.828 0 1.602-.203.781-.203 1.547-.61v1.36q-.774.328-1.586.5-.813.172-1.649.172-2.093 0-3.32-1.22-1.219-1.218-1.219-3.296 0-2.148 1.157-3.406 1.164-1.266 3.132-1.266 1.766 0 2.79 1.14 1.03 1.134 1.03 3.087zm-1.438-.422q-.015-1.18-.664-1.883-.64-.703-1.703-.703-1.203 0-1.93.68-.718.68-.828 1.914z\"/></g><g transform=\"translate(200, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M26.555 9.68v.703h-6.61q.094 1.484.89 2.265.806.774 2.235.774.828 0 1.602-.203.781-.203 1.547-.61v1.36q-.774.328-1.586.5-.813.172-1.649.172-2.093 0-3.32-1.22-1.219-1.218-1.219-3.296 0-2.148 1.157-3.406 1.164-1.266 3.132-1.266 1.766 0 2.79 1.14 1.03 1.134 1.03 3.087zm-1.438-.422q-.015-1.18-.664-1.883-.64-.703-1.703-.703-1.203 0-1.93.68-.718.68-.828 1.914z\"/></g><g transform=\"translate(245, 1) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M25.285 2.258v1.195H23.91q-.773 0-1.078.313-.297.312-.297 1.125v.773h2.367v1.117h-2.367v7.633H21.09V6.781h-1.375V5.664h1.375v-.61q0-1.46.68-2.124.68-.672 2.156-.672z\"/></g><g transform=\"translate(245, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M25.285 2.258v1.195H23.91q-.773 0-1.078.313-.297.312-.297 1.125v.773h2.367v1.117h-2.367v7.633H21.09V6.781h-1.375V5.664h1.375v-.61q0-1.46.68-2.124.68-.672 2.156-.672z\"/></g><g transform=\"translate(290, 1) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.973 9.937q0-1.562-.649-2.421-.64-.86-1.804-.86-1.157 0-1.805.86-.64.859-.64 2.421 0 1.555.64 2.415.648.859 1.805.859 1.164 0 1.804-.86.649-.859.649-2.414zm1.437 3.391q0 2.234-.992 3.32-.992 1.094-3.04 1.094-.757 0-1.429-.117-.672-.11-1.304-.344v-1.398q.632.344 1.25.508.617.164 1.257.164 1.414 0 2.118-.743.703-.734.703-2.226v-.711q-.446.773-1.141 1.156-.695.383-1.664.383-1.61 0-2.594-1.227-.984-1.226-.984-3.25 0-2.03.984-3.257.985-1.227 2.594-1.227.969 0 1.664.383t1.14 1.156V5.664h1.438z\"/></g><g transform=\"translate(290, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.973 9.937q0-1.562-.649-2.421-.64-.86-1.804-.86-1.157 0-1.805.86-.64.859-.64 2.421 0 1.555.64 2.415.648.859 1.805.859 1.164 0 1.804-.86.649-.859.649-2.414zm1.437 3.391q0 2.234-.992 3.32-.992 1.094-3.04 1.094-.757 0-1.429-.117-.672-.11-1.304-.344v-1.398q.632.344 1.25.508.617.164 1.257.164 1.414 0 2.118-.743.703-.734.703-2.226v-.711q-.446.773-1.141 1.156-.695.383-1.664.383-1.61 0-2.594-1.227-.984-1.226-.984-3.25 0-2.03.984-3.257.985-1.227 2.594-1.227.969 0 1.664.383t1.14 1.156V5.664h1.438z\"/></g><g transform=\"translate(335, 1) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M26.164 9.133v5.281h-1.437V9.18q0-1.243-.485-1.86-.484-.617-1.453-.617-1.164 0-1.836.742-.672.742-.672 2.024v4.945h-1.445V2.258h1.445v4.765q.516-.789 1.211-1.18.703-.39 1.617-.39 1.508 0 2.282.938.773.93.773 2.742z\"/></g><g transform=\"translate(335, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M26.164 9.133v5.281h-1.437V9.18q0-1.243-.485-1.86-.484-.617-1.453-.617-1.164 0-1.836.742-.672.742-.672 2.024v4.945h-1.445V2.258h1.445v4.765q.516-.789 1.211-1.18.703-.39 1.617-.39 1.508 0 2.282.938.773.93.773 2.742z\"/></g><g transform=\"translate(0, 335) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.754 26.996h2.578v-8.898l-2.805.562v-1.437l2.79-.563h1.578v10.336h2.578v1.328h-6.72z\"/></g><g transform=\"translate(375, 335) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.754 26.996h2.578v-8.898l-2.805.562v-1.437l2.79-.563h1.578v10.336h2.578v1.328h-6.72z\"/></g><g transform=\"translate(0, 290) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M8.195 26.996h5.508v1.328H6.297v-1.328q.898-.93 2.445-2.492 1.555-1.57 1.953-2.024.758-.851 1.055-1.437.305-.594.305-1.164 0-.93-.657-1.516-.648-.586-1.695-.586-.742 0-1.57.258-.82.258-1.758.781v-1.593q.953-.383 1.781-.578.828-.196 1.516-.196 1.812 0 2.89.906 1.079.907 1.079 2.422 0 .72-.274 1.368-.265.64-.976 1.515-.196.227-1.243 1.313-1.046 1.078-2.953 3.023z\"/></g><g transform=\"translate(375, 290) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M8.195 26.996h5.508v1.328H6.297v-1.328q.898-.93 2.445-2.492 1.555-1.57 1.953-2.024.758-.851 1.055-1.437.305-.594.305-1.164 0-.93-.657-1.516-.648-.586-1.695-.586-.742 0-1.57.258-.82.258-1.758.781v-1.593q.953-.383 1.781-.578.828-.196 1.516-.196 1.812 0 2.89.906 1.079.907 1.079 2.422 0 .72-.274 1.368-.265.64-.976 1.515-.196.227-1.243 1.313-1.046 1.078-2.953 3.023z\"/></g><g transform=\"translate(0, 245) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M11.434 22.035q1.132.242 1.765 1.008.64.766.64 1.89 0 1.727-1.187 2.672-1.187.946-3.375.946-.734 0-1.515-.149-.774-.14-1.602-.43V26.45q.656.383 1.438.578.78.196 1.632.196 1.485 0 2.258-.586.782-.586.782-1.703 0-1.032-.727-1.61-.719-.586-2.008-.586h-1.36v-1.297h1.423q1.164 0 1.78-.46.618-.47.618-1.344 0-.899-.64-1.375-.633-.485-1.82-.485-.65 0-1.391.141-.743.14-1.633.437V16.95q.898-.25 1.68-.375.788-.125 1.484-.125 1.797 0 2.844.82 1.046.813 1.046 2.204 0 .968-.554 1.64-.555.664-1.578.922z\"/></g><g transform=\"translate(375, 245) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M11.434 22.035q1.132.242 1.765 1.008.64.766.64 1.89 0 1.727-1.187 2.672-1.187.946-3.375.946-.734 0-1.515-.149-.774-.14-1.602-.43V26.45q.656.383 1.438.578.78.196 1.632.196 1.485 0 2.258-.586.782-.586.782-1.703 0-1.032-.727-1.61-.719-.586-2.008-.586h-1.36v-1.297h1.423q1.164 0 1.78-.46.618-.47.618-1.344 0-.899-.64-1.375-.633-.485-1.82-.485-.65 0-1.391.141-.743.14-1.633.437V16.95q.898-.25 1.68-.375.788-.125 1.484-.125 1.797 0 2.844.82 1.046.813 1.046 2.204 0 .968-.554 1.64-.555.664-1.578.922z\"/></g><g transform=\"translate(0, 200) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M11.016 18.035L7.03 24.262h3.985zm-.414-1.375h1.984v7.602h1.664v1.312h-1.664v2.75h-1.57v-2.75H5.75v-1.523z\"/></g><g transform=\"translate(375, 200) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M11.016 18.035L7.03 24.262h3.985zm-.414-1.375h1.984v7.602h1.664v1.312h-1.664v2.75h-1.57v-2.75H5.75v-1.523z\"/></g><g transform=\"translate(0, 155) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.719 16.66h6.195v1.328h-4.75v2.86q.344-.118.688-.172.343-.063.687-.063 1.953 0 3.094 1.07 1.14 1.07 1.14 2.899 0 1.883-1.171 2.93-1.172 1.039-3.305 1.039-.735 0-1.5-.125-.758-.125-1.57-.375v-1.586q.703.383 1.453.57.75.188 1.586.188 1.351 0 2.14-.711.79-.711.79-1.93 0-1.219-.79-1.93-.789-.71-2.14-.71-.633 0-1.266.14-.625.14-1.281.438z\"/></g><g transform=\"translate(375, 155) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.719 16.66h6.195v1.328h-4.75v2.86q.344-.118.688-.172.343-.063.687-.063 1.953 0 3.094 1.07 1.14 1.07 1.14 2.899 0 1.883-1.171 2.93-1.172 1.039-3.305 1.039-.735 0-1.5-.125-.758-.125-1.57-.375v-1.586q.703.383 1.453.57.75.188 1.586.188 1.351 0 2.14-.711.79-.711.79-1.93 0-1.219-.79-1.93-.789-.71-2.14-.71-.633 0-1.266.14-.625.14-1.281.438z\"/></g><g transform=\"translate(0, 110) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M10.137 21.863q-1.063 0-1.688.727-.617.726-.617 1.992 0 1.258.617 1.992.625.727 1.688.727 1.062 0 1.68-.727.624-.734.624-1.992 0-1.266-.625-1.992-.617-.727-1.68-.727zm3.133-4.945v1.437q-.594-.28-1.204-.43-.601-.148-1.195-.148-1.562 0-2.39 1.055-.82 1.055-.938 3.188.46-.68 1.156-1.04.696-.367 1.531-.367 1.758 0 2.774 1.07 1.023 1.063 1.023 2.899 0 1.797-1.062 2.883-1.063 1.086-2.828 1.086-2.024 0-3.094-1.547-1.07-1.555-1.07-4.5 0-2.766 1.312-4.406 1.313-1.649 3.524-1.649.593 0 1.195.117.61.118 1.266.352z\"/></g><g transform=\"translate(375, 110) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M10.137 21.863q-1.063 0-1.688.727-.617.726-.617 1.992 0 1.258.617 1.992.625.727 1.688.727 1.062 0 1.68-.727.624-.734.624-1.992 0-1.266-.625-1.992-.617-.727-1.68-.727zm3.133-4.945v1.437q-.594-.28-1.204-.43-.601-.148-1.195-.148-1.562 0-2.39 1.055-.82 1.055-.938 3.188.46-.68 1.156-1.04.696-.367 1.531-.367 1.758 0 2.774 1.07 1.023 1.063 1.023 2.899 0 1.797-1.062 2.883-1.063 1.086-2.828 1.086-2.024 0-3.094-1.547-1.07-1.555-1.07-4.5 0-2.766 1.312-4.406 1.313-1.649 3.524-1.649.593 0 1.195.117.61.118 1.266.352z\"/></g><g transform=\"translate(0, 65) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.25 16.66h7.5v.672L9.516 28.324H7.867l3.985-10.336H6.25z\"/></g><g transform=\"translate(375, 65) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.25 16.66h7.5v.672L9.516 28.324H7.867l3.985-10.336H6.25z\"/></g><g transform=\"translate(0, 20) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M10 22.785q-1.125 0-1.773.602-.641.601-.641 1.656t.64 1.656q.649.602 1.774.602t1.773-.602q.649-.61.649-1.656 0-1.055-.649-1.656-.64-.602-1.773-.602zm-1.578-.672q-1.016-.25-1.586-.945-.563-.695-.563-1.695 0-1.399.993-2.211 1-.813 2.734-.813 1.742 0 2.734.813.993.812.993 2.21 0 1-.57 1.696-.563.695-1.571.945 1.14.266 1.773 1.04.641.773.641 1.89 0 1.695-1.04 2.602-1.03.906-2.96.906t-2.969-.906Q6 26.738 6 25.043q0-1.117.64-1.89.641-.774 1.782-1.04zm-.578-2.492q0 .906.562 1.414.57.508 1.594.508 1.016 0 1.586-.508.578-.508.578-1.414 0-.906-.578-1.414-.57-.508-1.586-.508-1.023 0-1.594.508-.562.508-.562 1.414z\"/></g><g transform=\"translate(375, 20) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M10 22.785q-1.125 0-1.773.602-.641.601-.641 1.656t.64 1.656q.649.602 1.774.602t1.773-.602q.649-.61.649-1.656 0-1.055-.649-1.656-.64-.602-1.773-.602zm-1.578-.672q-1.016-.25-1.586-.945-.563-.695-.563-1.695 0-1.399.993-2.211 1-.813 2.734-.813 1.742 0 2.734.813.993.812.993 2.21 0 1-.57 1.696-.563.695-1.571.945 1.14.266 1.773 1.04.641.773.641 1.89 0 1.695-1.04 2.602-1.03.906-2.96.906t-2.969-.906Q6 26.738 6 25.043q0-1.117.64-1.89.641-.774 1.782-1.04zm-.578-2.492q0 .906.562 1.414.57.508 1.594.508 1.016 0 1.586-.508.578-.508.578-1.414 0-.906-.578-1.414-.57-.508-1.586-.508-1.023 0-1.594.508-.562.508-.562 1.414z\"/></g><rect x=\"15\" y=\"330\" width=\"45\" height=\"45\" class=\"square dark a1\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"60\" y=\"330\" width=\"45\" height=\"45\" class=\"square light b1\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"105\" y=\"330\" width=\"45\" height=\"45\" class=\"square dark c1\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"150\" y=\"330\" width=\"45\" height=\"45\" class=\"square light d1\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"195\" y=\"330\" width=\"45\" height=\"45\" class=\"square dark e1\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"240\" y=\"330\" width=\"45\" height=\"45\" class=\"square light f1\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"285\" y=\"330\" width=\"45\" height=\"45\" class=\"square dark g1\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"330\" y=\"330\" width=\"45\" height=\"45\" class=\"square light h1\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"15\" y=\"285\" width=\"45\" height=\"45\" class=\"square light a2\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"60\" y=\"285\" width=\"45\" height=\"45\" class=\"square dark b2\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"105\" y=\"285\" width=\"45\" height=\"45\" class=\"square light c2\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"150\" y=\"285\" width=\"45\" height=\"45\" class=\"square dark d2\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"195\" y=\"285\" width=\"45\" height=\"45\" class=\"square light e2\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"240\" y=\"285\" width=\"45\" height=\"45\" class=\"square dark f2\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"285\" y=\"285\" width=\"45\" height=\"45\" class=\"square light g2\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"330\" y=\"285\" width=\"45\" height=\"45\" class=\"square dark h2\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"15\" y=\"240\" width=\"45\" height=\"45\" class=\"square dark a3\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"60\" y=\"240\" width=\"45\" height=\"45\" class=\"square light b3\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"105\" y=\"240\" width=\"45\" height=\"45\" class=\"square dark c3\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"150\" y=\"240\" width=\"45\" height=\"45\" class=\"square light d3\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"195\" y=\"240\" width=\"45\" height=\"45\" class=\"square dark e3\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"240\" y=\"240\" width=\"45\" height=\"45\" class=\"square light f3\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"285\" y=\"240\" width=\"45\" height=\"45\" class=\"square dark g3\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"330\" y=\"240\" width=\"45\" height=\"45\" class=\"square light h3\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"15\" y=\"195\" width=\"45\" height=\"45\" class=\"square light a4\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"60\" y=\"195\" width=\"45\" height=\"45\" class=\"square dark b4\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"105\" y=\"195\" width=\"45\" height=\"45\" class=\"square light c4\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"150\" y=\"195\" width=\"45\" height=\"45\" class=\"square dark d4\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"195\" y=\"195\" width=\"45\" height=\"45\" class=\"square light e4\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"240\" y=\"195\" width=\"45\" height=\"45\" class=\"square dark f4\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"285\" y=\"195\" width=\"45\" height=\"45\" class=\"square light g4\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"330\" y=\"195\" width=\"45\" height=\"45\" class=\"square dark h4\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"15\" y=\"150\" width=\"45\" height=\"45\" class=\"square dark a5\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"60\" y=\"150\" width=\"45\" height=\"45\" class=\"square light b5\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"105\" y=\"150\" width=\"45\" height=\"45\" class=\"square dark c5\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"150\" y=\"150\" width=\"45\" height=\"45\" class=\"square light d5\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"195\" y=\"150\" width=\"45\" height=\"45\" class=\"square dark e5\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"240\" y=\"150\" width=\"45\" height=\"45\" class=\"square light f5\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"285\" y=\"150\" width=\"45\" height=\"45\" class=\"square dark g5\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"330\" y=\"150\" width=\"45\" height=\"45\" class=\"square light h5\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"15\" y=\"105\" width=\"45\" height=\"45\" class=\"square light a6\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"60\" y=\"105\" width=\"45\" height=\"45\" class=\"square dark b6\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"105\" y=\"105\" width=\"45\" height=\"45\" class=\"square light c6\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"150\" y=\"105\" width=\"45\" height=\"45\" class=\"square dark d6\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"195\" y=\"105\" width=\"45\" height=\"45\" class=\"square light e6\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"240\" y=\"105\" width=\"45\" height=\"45\" class=\"square dark f6\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"285\" y=\"105\" width=\"45\" height=\"45\" class=\"square light g6\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"330\" y=\"105\" width=\"45\" height=\"45\" class=\"square dark h6\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"15\" y=\"60\" width=\"45\" height=\"45\" class=\"square dark a7\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"60\" y=\"60\" width=\"45\" height=\"45\" class=\"square light b7\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"105\" y=\"60\" width=\"45\" height=\"45\" class=\"square dark c7\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"150\" y=\"60\" width=\"45\" height=\"45\" class=\"square light d7\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"195\" y=\"60\" width=\"45\" height=\"45\" class=\"square dark e7\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"240\" y=\"60\" width=\"45\" height=\"45\" class=\"square light f7\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"285\" y=\"60\" width=\"45\" height=\"45\" class=\"square dark g7\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"330\" y=\"60\" width=\"45\" height=\"45\" class=\"square light h7\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"15\" y=\"15\" width=\"45\" height=\"45\" class=\"square light a8\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"60\" y=\"15\" width=\"45\" height=\"45\" class=\"square dark b8\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"105\" y=\"15\" width=\"45\" height=\"45\" class=\"square light c8\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"150\" y=\"15\" width=\"45\" height=\"45\" class=\"square dark d8\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"195\" y=\"15\" width=\"45\" height=\"45\" class=\"square light e8\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"240\" y=\"15\" width=\"45\" height=\"45\" class=\"square dark f8\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"285\" y=\"15\" width=\"45\" height=\"45\" class=\"square light g8\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"330\" y=\"15\" width=\"45\" height=\"45\" class=\"square dark h8\" stroke=\"none\" fill=\"#d18b47\"/><use href=\"#white-rook\" xlink:href=\"#white-rook\" transform=\"translate(15, 330)\"/><use href=\"#white-knight\" xlink:href=\"#white-knight\" transform=\"translate(60, 330)\"/><use href=\"#white-bishop\" xlink:href=\"#white-bishop\" transform=\"translate(105, 330)\"/><use href=\"#white-queen\" xlink:href=\"#white-queen\" transform=\"translate(150, 330)\"/><use href=\"#white-king\" xlink:href=\"#white-king\" transform=\"translate(195, 330)\"/><use href=\"#white-bishop\" xlink:href=\"#white-bishop\" transform=\"translate(240, 330)\"/><use href=\"#white-knight\" xlink:href=\"#white-knight\" transform=\"translate(285, 330)\"/><use href=\"#white-rook\" xlink:href=\"#white-rook\" transform=\"translate(330, 330)\"/><use href=\"#white-pawn\" xlink:href=\"#white-pawn\" transform=\"translate(15, 285)\"/><use href=\"#white-pawn\" xlink:href=\"#white-pawn\" transform=\"translate(60, 285)\"/><use href=\"#white-pawn\" xlink:href=\"#white-pawn\" transform=\"translate(105, 285)\"/><use href=\"#white-pawn\" xlink:href=\"#white-pawn\" transform=\"translate(150, 285)\"/><use href=\"#white-pawn\" xlink:href=\"#white-pawn\" transform=\"translate(195, 285)\"/><use href=\"#white-pawn\" xlink:href=\"#white-pawn\" transform=\"translate(240, 285)\"/><use href=\"#white-pawn\" xlink:href=\"#white-pawn\" transform=\"translate(285, 285)\"/><use href=\"#white-pawn\" xlink:href=\"#white-pawn\" transform=\"translate(330, 285)\"/><use href=\"#black-pawn\" xlink:href=\"#black-pawn\" transform=\"translate(15, 60)\"/><use href=\"#black-pawn\" xlink:href=\"#black-pawn\" transform=\"translate(60, 60)\"/><use href=\"#black-pawn\" xlink:href=\"#black-pawn\" transform=\"translate(105, 60)\"/><use href=\"#black-pawn\" xlink:href=\"#black-pawn\" transform=\"translate(150, 60)\"/><use href=\"#black-pawn\" xlink:href=\"#black-pawn\" transform=\"translate(195, 60)\"/><use href=\"#black-pawn\" xlink:href=\"#black-pawn\" transform=\"translate(240, 60)\"/><use href=\"#black-pawn\" xlink:href=\"#black-pawn\" transform=\"translate(285, 60)\"/><use href=\"#black-pawn\" xlink:href=\"#black-pawn\" transform=\"translate(330, 60)\"/><use href=\"#black-rook\" xlink:href=\"#black-rook\" transform=\"translate(15, 15)\"/><use href=\"#black-knight\" xlink:href=\"#black-knight\" transform=\"translate(60, 15)\"/><use href=\"#black-bishop\" xlink:href=\"#black-bishop\" transform=\"translate(105, 15)\"/><use href=\"#black-queen\" xlink:href=\"#black-queen\" transform=\"translate(150, 15)\"/><use href=\"#black-king\" xlink:href=\"#black-king\" transform=\"translate(195, 15)\"/><use href=\"#black-bishop\" xlink:href=\"#black-bishop\" transform=\"translate(240, 15)\"/><use href=\"#black-knight\" xlink:href=\"#black-knight\" transform=\"translate(285, 15)\"/><use href=\"#black-rook\" xlink:href=\"#black-rook\" transform=\"translate(330, 15)\"/></svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Move History:\n",
      "Full history: \n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    game = ChessGame()\n",
    "    game.play_game(my_moves_generator)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
