{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-05-21T08:47:07.338294Z",
     "iopub.status.busy": "2025-05-21T08:47:07.337758Z",
     "iopub.status.idle": "2025-05-21T08:47:07.605532Z",
     "shell.execute_reply": "2025-05-21T08:47:07.604772Z",
     "shell.execute_reply.started": "2025-05-21T08:47:07.338267Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/chess-games/chess_games(1).db\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-21T08:47:07.607359Z",
     "iopub.status.busy": "2025-05-21T08:47:07.607052Z",
     "iopub.status.idle": "2025-05-21T08:47:37.692055Z",
     "shell.execute_reply": "2025-05-21T08:47:37.691457Z",
     "shell.execute_reply.started": "2025-05-21T08:47:07.607337Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-21 08:47:22.963781: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1747817243.205980      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1747817243.271074      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import sqlite3 as sq\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import (\n",
    "    GPT2Tokenizer, GPT2LMHeadModel, DataCollatorForLanguageModeling,\n",
    "    Trainer, TrainingArguments, TextDataset\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first the reduced dataset were on a DB with 100k matches, due to that the fineTuning was on 90k matches leaving the other 10k for testing/validation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PARAMETER SELECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-21T08:54:49.070858Z",
     "iopub.status.busy": "2025-05-21T08:54:49.070588Z",
     "iopub.status.idle": "2025-05-21T08:54:49.075696Z",
     "shell.execute_reply": "2025-05-21T08:54:49.074822Z",
     "shell.execute_reply.started": "2025-05-21T08:54:49.070838Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# PARAMETERS (modify if needed)\n",
    "DB_PATH = \"/kaggle/input/chess-games/chess_games(1).db\"\n",
    "TRAIN_SIZE = 90000\n",
    "TEST_SIZE = 10000\n",
    "BLOCK_SIZE = 256\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 4\n",
    "LEARNING_RATE = 5e-5\n",
    "OUTPUT_DIR = \"/kaggle/working/chess_gpt2_outputV2\"\n",
    "LOG_FILE = os.path.join(OUTPUT_DIR, \"eval_log.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create the traning dataset as the sequence of moves within each game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-21T08:47:37.698434Z",
     "iopub.status.busy": "2025-05-21T08:47:37.698167Z",
     "iopub.status.idle": "2025-05-21T08:48:31.405110Z",
     "shell.execute_reply": "2025-05-21T08:48:31.404426Z",
     "shell.execute_reply.started": "2025-05-21T08:47:37.698412Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Load data from DB\n",
    "conn = sq.connect(DB_PATH)\n",
    "df = pd.read_sql(\"SELECT game_id, move_number, move FROM moves ORDER BY game_id, move_number\", conn)\n",
    "games = df.groupby(\"game_id\")[\"move\"].apply(lambda x: ' '.join(x)).tolist()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and Test set division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-21T08:48:31.407345Z",
     "iopub.status.busy": "2025-05-21T08:48:31.407067Z",
     "iopub.status.idle": "2025-05-21T08:48:31.470318Z",
     "shell.execute_reply": "2025-05-21T08:48:31.469540Z",
     "shell.execute_reply.started": "2025-05-21T08:48:31.407326Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "SEED = 42  # Relevant for the legality rate used for evaluate the model in zeroShot\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)  \n",
    "torch.manual_seed(SEED) \n",
    "\n",
    "# Sample and split\n",
    "games = random.sample(games, min(len(games), TRAIN_SIZE + TEST_SIZE))\n",
    "\n",
    "train_games, test_games = train_test_split(\n",
    "    games,\n",
    "    test_size=TEST_SIZE,\n",
    "    random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-21T08:54:58.816422Z",
     "iopub.status.busy": "2025-05-21T08:54:58.815700Z",
     "iopub.status.idle": "2025-05-21T08:54:58.821702Z",
     "shell.execute_reply": "2025-05-21T08:54:58.820835Z",
     "shell.execute_reply.started": "2025-05-21T08:54:58.816396Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class ChessGameDataset(Dataset):\n",
    "    def __init__(self, games, tokenizer, block_size=128):\n",
    "        self.examples = []\n",
    "        for game in games:\n",
    "            tokens = tokenizer(game + tokenizer.eos_token, truncation=True, max_length=block_size, padding=\"max_length\")\n",
    "            self.examples.append(torch.tensor(tokens[\"input_ids\"]))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.examples)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return {\"input_ids\": self.examples[i], \"labels\": self.examples[i]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPT2 FineTuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-21T08:48:31.477103Z",
     "iopub.status.busy": "2025-05-21T08:48:31.476885Z",
     "iopub.status.idle": "2025-05-21T08:48:36.914668Z",
     "shell.execute_reply": "2025-05-21T08:48:36.913855Z",
     "shell.execute_reply.started": "2025-05-21T08:48:31.477079Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c300763d88e04349878975802f5d7cf9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06e53309ae994b089359aa9cf5734a56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24e2edd81add41009d4270d2e8f1f788",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c7a5be6cd794812b98850e03e66509c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cb9107c9d034428bef86b6485cd0b72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0ed5721e39949798ff32f63093bb1b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c62b44ac2544f099da1a1bb4f3df1f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Embedding(50257, 768)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "tokenizer.pad_token = tokenizer.eos_token  # necessary for padding\n",
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-21T08:55:02.062828Z",
     "iopub.status.busy": "2025-05-21T08:55:02.062036Z",
     "iopub.status.idle": "2025-05-21T09:00:29.263753Z",
     "shell.execute_reply": "2025-05-21T09:00:29.263190Z",
     "shell.execute_reply.started": "2025-05-21T08:55:02.062798Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Prepare datasets\n",
    "dataset_train = ChessGameDataset(train_games, tokenizer, BLOCK_SIZE)\n",
    "dataset_test = ChessGameDataset(test_games, tokenizer, BLOCK_SIZE)\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-21T09:00:53.066076Z",
     "iopub.status.busy": "2025-05-21T09:00:53.065777Z",
     "iopub.status.idle": "2025-05-21T09:00:53.093402Z",
     "shell.execute_reply": "2025-05-21T09:00:53.092823Z",
     "shell.execute_reply.started": "2025-05-21T09:00:53.066056Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=EPOCHS,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    logging_dir=OUTPUT_DIR,\n",
    "    logging_steps=10,\n",
    "    report_to=\"none\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-21T09:00:55.169990Z",
     "iopub.status.busy": "2025-05-21T09:00:55.169484Z",
     "iopub.status.idle": "2025-05-21T09:00:55.174894Z",
     "shell.execute_reply": "2025-05-21T09:00:55.174113Z",
     "shell.execute_reply.started": "2025-05-21T09:00:55.169937Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def compute_accuracy(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = torch.argmax(torch.tensor(logits), dim=-1)\n",
    "    labels = torch.tensor(labels)\n",
    "    mask = labels != -100\n",
    "    correct = (predictions == labels) & mask\n",
    "    accuracy = correct.sum().item() / mask.sum().item()\n",
    "    with open(LOG_FILE, \"a\") as f:\n",
    "        f.write(f\"Accuracy: {accuracy:.4f}\\n\")\n",
    "    return {\"accuracy\": accuracy}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fine Tuning and saving of the evaluation obtained(the actual directory has been changed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-21T09:00:57.587447Z",
     "iopub.status.busy": "2025-05-21T09:00:57.586835Z",
     "iopub.status.idle": "2025-05-21T12:38:54.513841Z",
     "shell.execute_reply": "2025-05-21T12:38:54.513164Z",
     "shell.execute_reply.started": "2025-05-21T09:00:57.587415Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 5625/5625 [52:39<00:00,  1.78it/s, loss=0.781]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 - Accuracy: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 5625/5625 [52:40<00:00,  1.78it/s, loss=0.732]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Accuracy: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 5625/5625 [52:41<00:00,  1.78it/s, loss=0.704]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 - Accuracy: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 5625/5625 [52:42<00:00,  1.78it/s, loss=0.626]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 - Accuracy: 0.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('/kaggle/working/chess_gpt2_outputV2/model/tokenizer_config.json',\n",
       " '/kaggle/working/chess_gpt2_outputV2/model/special_tokens_map.json',\n",
       " '/kaggle/working/chess_gpt2_outputV2/model/vocab.json',\n",
       " '/kaggle/working/chess_gpt2_outputV2/model/merges.txt',\n",
       " '/kaggle/working/chess_gpt2_outputV2/model/added_tokens.json')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "LOG_FILE = \"/kaggle/working/chess_gpt2_outputV2/eval_log.txt\"\n",
    "\n",
    "os.makedirs(os.path.dirname(LOG_FILE), exist_ok=True)\n",
    "# Device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "model.train()\n",
    "\n",
    "# Dataloader\n",
    "train_loader = DataLoader(\n",
    "    dataset_train,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    collate_fn=data_collator\n",
    ")\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# Training + evaluation for epochs\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    loop = tqdm(train_loader, desc=f\"Epoch {epoch}\")\n",
    "    for batch in loop:\n",
    "        inputs = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model(**inputs)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        model.zero_grad()\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "\n",
    "    # === EVALUATION ===\n",
    "    model.eval()\n",
    "    eval_loader = DataLoader(\n",
    "        dataset_test,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=False,\n",
    "        collate_fn=data_collator\n",
    "    )\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in eval_loader:\n",
    "            inputs = {k: v.to(device) for k, v in batch.items()}\n",
    "            outputs = model(**inputs)\n",
    "            logits = outputs.logits\n",
    "            predictions = torch.argmax(logits, dim=-1)\n",
    "            labels = inputs[\"labels\"]\n",
    "            mask = labels != -100\n",
    "            correct += ((predictions == labels) & mask).sum().item()\n",
    "            total += mask.sum().item()\n",
    "\n",
    "    accuracy = correct / total\n",
    "    with open(LOG_FILE, \"a\") as f:\n",
    "        f.write(f\"Epoch {epoch}: Accuracy = {accuracy:.4f}\\n\")\n",
    "    print(f\"Epoch {epoch} - Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Save model and tokenizer\n",
    "model.save_pretrained(os.path.join(OUTPUT_DIR, \"model\"))\n",
    "tokenizer.save_pretrained(os.path.join(OUTPUT_DIR, \"model\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next token accuracy remain strangely at 0.0000 through al the epochs which is strange but in the zeroShot can be seen that the model has actually improve is ability in generating moves from a moveHistory\n",
    "\n",
    "This could be due to a great variability of the next moves possibilities or to the low dimension of the dataset used"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7434303,
     "sourceId": 11833538,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
